{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47513dd",
   "metadata": {},
   "source": [
    "# **Task11**\n",
    "\n",
    "Use the code from: https://medium.com/@rekalantar/pytorch-tutorial-dynamic-weight-pruning-for-more-optimized-and-faster-neural-networks-7b337e47987b to do dynamic weight pruning. If the full dataset is too large use a suitable subset size.\n",
    "\n",
    "Use post-training static quantization as well as dynamic quantization as given in: https://pytorch.org/tutorials/recipes/quantization.html to generate a dynamic weight pruning+quantized model. Compare accuracy of the quantized model vs the non-quantized model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05168766",
   "metadata": {},
   "source": [
    "## Importing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9ebe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchsummary\n",
    "from torchvision import models, datasets\n",
    "from timeit import default_timer as timer\n",
    "import torch.quantization as quant\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3064a06",
   "metadata": {},
   "source": [
    "Checking for device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad99818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd4496",
   "metadata": {},
   "source": [
    "Loading the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5750ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "# Load and subset the dataset\n",
    "full_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(full_dataset, batch_size=100, shuffle=True)\n",
    "# Load the test dataset\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70233ea",
   "metadata": {},
   "source": [
    "# Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9614173",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, input_channels, out_planes, stride= 1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, out_planes, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 =  nn.Conv2d(out_planes, out_planes, kernel_size=3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.downsample = downsample\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        # Notice the addition operation in both scenarios\n",
    "        x  = self.skip_add.add(x, identity)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_channels =3 ,num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.input_channels = 64\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.input_channels, kernel_size = 7, stride = 2, padding = 3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.input_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, layers[0], out=64,  stride= 1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], out=128, stride= 2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], out=256, stride= 2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], out=512, stride= 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def _make_layer(self, block, residual_blocks ,out, stride):\n",
    "        downsample = None\n",
    "        layers = []\n",
    "        if stride != 1 or self.input_channels != out:\n",
    "            downsample = nn.Sequential(nn.Conv2d(self.input_channels, out, kernel_size=1, stride= stride),\n",
    "                                       nn.BatchNorm2d(out))\n",
    "        layers.append(block(self.input_channels, out, stride, downsample))\n",
    "        self.input_channels = out\n",
    "        for _ in range(1, residual_blocks):\n",
    "            layers.append(block(self.input_channels, out))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input are quantized\n",
    "        x = self.quant(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dequant(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d0ebfd",
   "metadata": {},
   "source": [
    "Calling the model ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd8239f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ffd7b8",
   "metadata": {},
   "source": [
    "### Defining the optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8bc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799239f8",
   "metadata": {},
   "source": [
    "### Function to count the zero parameters in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943720bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zero_params(model):\n",
    "    zero_count = 0\n",
    "    for param in model.parameters():\n",
    "        zero_count += torch.sum(param == 0).item()\n",
    "    return zero_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb490981",
   "metadata": {},
   "source": [
    "Printing the No.of Zero parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f46d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4801\n"
     ]
    }
   ],
   "source": [
    "before_pruning = count_zero_params(model)\n",
    "print(before_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee1acc",
   "metadata": {},
   "source": [
    "Printing the weights of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e592e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights:\n",
      " Parameter containing:\n",
      "tensor([[[[ 0.0517, -0.0364,  0.0254,  ...,  0.0388,  0.0648,  0.0686],\n",
      "          [ 0.0620,  0.0512,  0.0271,  ..., -0.0539,  0.0640,  0.0584],\n",
      "          [-0.0240, -0.0582,  0.0729,  ..., -0.0776,  0.0810,  0.0155],\n",
      "          ...,\n",
      "          [ 0.0545, -0.0712, -0.0585,  ..., -0.0130, -0.0214,  0.0099],\n",
      "          [-0.0768, -0.0390, -0.0125,  ..., -0.0373,  0.0256, -0.0721],\n",
      "          [ 0.0303,  0.0219, -0.0359,  ..., -0.0336,  0.0306,  0.0317]],\n",
      "\n",
      "         [[-0.0561, -0.0357, -0.0672,  ...,  0.0365,  0.0232,  0.0119],\n",
      "          [-0.0164, -0.0330,  0.0526,  ...,  0.0348, -0.0446,  0.0369],\n",
      "          [-0.0603, -0.0396, -0.0579,  ...,  0.0194,  0.0288, -0.0253],\n",
      "          ...,\n",
      "          [ 0.0471,  0.0602, -0.0717,  ...,  0.0816, -0.0549,  0.0257],\n",
      "          [-0.0797, -0.0068,  0.0176,  ...,  0.0160, -0.0575, -0.0629],\n",
      "          [ 0.0383, -0.0182,  0.0418,  ..., -0.0396,  0.0313, -0.0437]],\n",
      "\n",
      "         [[-0.0416,  0.0784,  0.0807,  ...,  0.0183,  0.0168, -0.0045],\n",
      "          [ 0.0647,  0.0548, -0.0128,  ..., -0.0076, -0.0287, -0.0070],\n",
      "          [ 0.0787,  0.0442, -0.0395,  ..., -0.0197, -0.0136, -0.0574],\n",
      "          ...,\n",
      "          [-0.0176, -0.0775,  0.0793,  ...,  0.0448, -0.0373, -0.0061],\n",
      "          [-0.0012,  0.0758,  0.0098,  ..., -0.0003,  0.0492,  0.0350],\n",
      "          [-0.0109, -0.0515,  0.0085,  ...,  0.0123,  0.0215,  0.0142]]],\n",
      "\n",
      "\n",
      "        [[[-0.0592,  0.0797,  0.0527,  ..., -0.0675, -0.0692,  0.0100],\n",
      "          [ 0.0735, -0.0613, -0.0784,  ...,  0.0759,  0.0343, -0.0581],\n",
      "          [-0.0078, -0.0467, -0.0635,  ...,  0.0307, -0.0057, -0.0620],\n",
      "          ...,\n",
      "          [ 0.0535, -0.0662,  0.0653,  ..., -0.0272,  0.0172, -0.0365],\n",
      "          [ 0.0532,  0.0073, -0.0373,  ...,  0.0751,  0.0344, -0.0142],\n",
      "          [-0.0509, -0.0739,  0.0347,  ...,  0.0608,  0.0467, -0.0049]],\n",
      "\n",
      "         [[ 0.0680, -0.0401, -0.0732,  ..., -0.0073, -0.0110,  0.0675],\n",
      "          [-0.0135,  0.0345,  0.0418,  ..., -0.0794,  0.0466, -0.0802],\n",
      "          [ 0.0229,  0.0399,  0.0470,  ..., -0.0178,  0.0509,  0.0037],\n",
      "          ...,\n",
      "          [-0.0819,  0.0033, -0.0012,  ..., -0.0012,  0.0621,  0.0349],\n",
      "          [ 0.0725, -0.0820,  0.0774,  ..., -0.0319, -0.0528,  0.0440],\n",
      "          [ 0.0783,  0.0321,  0.0527,  ...,  0.0541, -0.0090, -0.0719]],\n",
      "\n",
      "         [[-0.0347, -0.0761,  0.0153,  ...,  0.0803, -0.0286,  0.0463],\n",
      "          [-0.0556, -0.0308, -0.0172,  ...,  0.0545,  0.0556, -0.0444],\n",
      "          [-0.0166,  0.0290,  0.0695,  ...,  0.0101,  0.0481, -0.0518],\n",
      "          ...,\n",
      "          [-0.0274, -0.0335, -0.0159,  ..., -0.0232, -0.0437,  0.0140],\n",
      "          [ 0.0213,  0.0498,  0.0275,  ..., -0.0511, -0.0501, -0.0740],\n",
      "          [ 0.0382, -0.0620, -0.0769,  ..., -0.0637,  0.0531,  0.0562]]],\n",
      "\n",
      "\n",
      "        [[[-0.0067, -0.0765,  0.0084,  ..., -0.0357,  0.0065,  0.0356],\n",
      "          [-0.0614, -0.0035,  0.0127,  ..., -0.0630,  0.0291, -0.0234],\n",
      "          [ 0.0596, -0.0305,  0.0588,  ...,  0.0618, -0.0486,  0.0226],\n",
      "          ...,\n",
      "          [ 0.0587, -0.0439,  0.0404,  ..., -0.0704,  0.0648, -0.0198],\n",
      "          [ 0.0236,  0.0289, -0.0550,  ..., -0.0199, -0.0516,  0.0111],\n",
      "          [-0.0053,  0.0381,  0.0143,  ...,  0.0304, -0.0406,  0.0219]],\n",
      "\n",
      "         [[-0.0391, -0.0393,  0.0816,  ...,  0.0545,  0.0231,  0.0180],\n",
      "          [ 0.0197, -0.0189, -0.0248,  ..., -0.0348, -0.0020, -0.0587],\n",
      "          [-0.0758, -0.0509,  0.0192,  ..., -0.0140,  0.0474,  0.0548],\n",
      "          ...,\n",
      "          [-0.0106, -0.0061,  0.0271,  ...,  0.0087,  0.0189,  0.0805],\n",
      "          [ 0.0248,  0.0799,  0.0034,  ...,  0.0623, -0.0025, -0.0166],\n",
      "          [-0.0347,  0.0058, -0.0539,  ...,  0.0743, -0.0008,  0.0678]],\n",
      "\n",
      "         [[ 0.0360, -0.0720, -0.0011,  ...,  0.0574,  0.0487,  0.0590],\n",
      "          [ 0.0273,  0.0530, -0.0203,  ..., -0.0287,  0.0426,  0.0089],\n",
      "          [ 0.0462, -0.0159,  0.0418,  ..., -0.0337,  0.0187,  0.0806],\n",
      "          ...,\n",
      "          [-0.0013, -0.0024, -0.0013,  ...,  0.0642, -0.0519,  0.0609],\n",
      "          [ 0.0215, -0.0186,  0.0337,  ..., -0.0823,  0.0409,  0.0572],\n",
      "          [ 0.0509,  0.0632,  0.0117,  ...,  0.0154,  0.0271, -0.0212]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0249, -0.0678, -0.0530,  ...,  0.0504, -0.0381, -0.0621],\n",
      "          [ 0.0396,  0.0673, -0.0468,  ...,  0.0732, -0.0554,  0.0320],\n",
      "          [-0.0013, -0.0096,  0.0777,  ...,  0.0149,  0.0278,  0.0363],\n",
      "          ...,\n",
      "          [ 0.0189,  0.0707, -0.0367,  ..., -0.0752,  0.0502, -0.0677],\n",
      "          [ 0.0655, -0.0036, -0.0150,  ..., -0.0115, -0.0528,  0.0671],\n",
      "          [-0.0365, -0.0033, -0.0636,  ..., -0.0175, -0.0533,  0.0105]],\n",
      "\n",
      "         [[-0.0752, -0.0356, -0.0373,  ...,  0.0225, -0.0347,  0.0807],\n",
      "          [-0.0061,  0.0400, -0.0805,  ..., -0.0112,  0.0785,  0.0018],\n",
      "          [ 0.0528,  0.0682, -0.0339,  ..., -0.0075,  0.0041,  0.0068],\n",
      "          ...,\n",
      "          [-0.0341, -0.0253, -0.0779,  ..., -0.0113,  0.0618, -0.0481],\n",
      "          [ 0.0384,  0.0507,  0.0053,  ...,  0.0681,  0.0244, -0.0755],\n",
      "          [ 0.0077, -0.0121, -0.0606,  ...,  0.0090,  0.0812, -0.0602]],\n",
      "\n",
      "         [[ 0.0224,  0.0165, -0.0296,  ..., -0.0595,  0.0013, -0.0731],\n",
      "          [ 0.0713, -0.0235, -0.0027,  ...,  0.0158, -0.0181,  0.0734],\n",
      "          [ 0.0701, -0.0679, -0.0680,  ...,  0.0439,  0.0215,  0.0124],\n",
      "          ...,\n",
      "          [ 0.0636, -0.0212, -0.0549,  ...,  0.0762, -0.0682, -0.0113],\n",
      "          [ 0.0200, -0.0183,  0.0512,  ...,  0.0546, -0.0543, -0.0252],\n",
      "          [-0.0605,  0.0705,  0.0547,  ...,  0.0453, -0.0395,  0.0764]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0534,  0.0054,  0.0774,  ..., -0.0278, -0.0804,  0.0224],\n",
      "          [ 0.0359, -0.0285,  0.0250,  ..., -0.0024, -0.0150, -0.0271],\n",
      "          [-0.0020, -0.0423,  0.0494,  ...,  0.0102, -0.0724,  0.0492],\n",
      "          ...,\n",
      "          [ 0.0097, -0.0044,  0.0525,  ...,  0.0638,  0.0362, -0.0724],\n",
      "          [-0.0537,  0.0703, -0.0153,  ...,  0.0468, -0.0050,  0.0482],\n",
      "          [-0.0798,  0.0391,  0.0571,  ..., -0.0408,  0.0620, -0.0675]],\n",
      "\n",
      "         [[-0.0486, -0.0539,  0.0355,  ...,  0.0167,  0.0578,  0.0529],\n",
      "          [-0.0459, -0.0421, -0.0660,  ..., -0.0394,  0.0611, -0.0792],\n",
      "          [ 0.0159, -0.0128,  0.0165,  ..., -0.0054, -0.0164, -0.0297],\n",
      "          ...,\n",
      "          [-0.0713,  0.0608,  0.0605,  ..., -0.0266,  0.0715,  0.0304],\n",
      "          [-0.0661, -0.0117, -0.0191,  ...,  0.0095,  0.0772, -0.0608],\n",
      "          [ 0.0357,  0.0107, -0.0492,  ..., -0.0258,  0.0009, -0.0038]],\n",
      "\n",
      "         [[-0.0772, -0.0535, -0.0728,  ...,  0.0736,  0.0348,  0.0674],\n",
      "          [ 0.0695,  0.0345, -0.0813,  ..., -0.0276,  0.0574,  0.0061],\n",
      "          [-0.0013, -0.0688,  0.0420,  ...,  0.0162, -0.0753,  0.0584],\n",
      "          ...,\n",
      "          [ 0.0622,  0.0262, -0.0149,  ...,  0.0298,  0.0722, -0.0324],\n",
      "          [ 0.0702,  0.0436, -0.0030,  ..., -0.0582, -0.0428,  0.0749],\n",
      "          [-0.0612, -0.0255, -0.0336,  ..., -0.0216, -0.0194, -0.0568]]],\n",
      "\n",
      "\n",
      "        [[[-0.0287,  0.0734,  0.0481,  ..., -0.0330, -0.0199,  0.0063],\n",
      "          [ 0.0607,  0.0225,  0.0602,  ..., -0.0160, -0.0596, -0.0455],\n",
      "          [ 0.0050, -0.0696,  0.0040,  ..., -0.0478, -0.0146,  0.0155],\n",
      "          ...,\n",
      "          [ 0.0138,  0.0131,  0.0107,  ...,  0.0213, -0.0603,  0.0096],\n",
      "          [ 0.0808, -0.0362, -0.0481,  ...,  0.0008, -0.0185,  0.0692],\n",
      "          [-0.0299, -0.0449, -0.0165,  ...,  0.0079,  0.0090, -0.0802]],\n",
      "\n",
      "         [[-0.0617, -0.0576,  0.0785,  ..., -0.0428, -0.0733,  0.0279],\n",
      "          [ 0.0289, -0.0204,  0.0475,  ...,  0.0443, -0.0433,  0.0767],\n",
      "          [-0.0082, -0.0215, -0.0578,  ..., -0.0124, -0.0804,  0.0598],\n",
      "          ...,\n",
      "          [-0.0532, -0.0431, -0.0296,  ...,  0.0617, -0.0052, -0.0711],\n",
      "          [-0.0333,  0.0280,  0.0525,  ...,  0.0615, -0.0619,  0.0108],\n",
      "          [ 0.0766, -0.0745,  0.0349,  ..., -0.0311,  0.0245,  0.0799]],\n",
      "\n",
      "         [[ 0.0641, -0.0544,  0.0189,  ...,  0.0060, -0.0035,  0.0071],\n",
      "          [ 0.0074,  0.0587, -0.0242,  ..., -0.0176,  0.0683, -0.0428],\n",
      "          [-0.0737, -0.0717, -0.0820,  ..., -0.0629, -0.0251,  0.0210],\n",
      "          ...,\n",
      "          [ 0.0606,  0.0310, -0.0242,  ..., -0.0752, -0.0633, -0.0108],\n",
      "          [-0.0439,  0.0478,  0.0508,  ...,  0.0187,  0.0694,  0.0596],\n",
      "          [-0.0196, -0.0245,  0.0321,  ...,  0.0287,  0.0739,  0.0676]]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original weights:\\n\", model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799cf298",
   "metadata": {},
   "source": [
    "Function to train the model and to do weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b24e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pruned_model(model, device, train_loader, optimizer, criterion,epochs,prune_epoch):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss : {running_loss / len(train_loader)}')       \n",
    "        \n",
    "        if (epoch+1) % prune_epoch == 0:\n",
    "            prune_model(model, pruning_rate=0.1)\n",
    "            print('Pruning done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61f1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def prune_model(model, pruning_rate=0.1):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "            \n",
    "            # Applying unstructured L1 norm pruning\n",
    "            prune.l1_unstructured(module, name='weight', amount=pruning_rate)\n",
    "            \n",
    "            prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c964b",
   "metadata": {},
   "source": [
    "Function to Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24862ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def evaluate_model(model,device):\n",
    "    model = model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            st = time.time()\n",
    "            outputs = model(images)\n",
    "            et = time.time()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct // total} %')\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ded267",
   "metadata": {},
   "source": [
    "## Calling the function train_model to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42f51eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss : 1.4925556901693344\n",
      "Epoch [2/15], Loss : 1.0655402550697326\n",
      "Epoch [3/15], Loss : 0.8518562903404235\n",
      "Epoch [4/15], Loss : 0.7238209476470947\n",
      "Epoch [5/15], Loss : 0.5991190549135208\n",
      "Pruning done.\n",
      "Epoch [6/15], Loss : 0.5140401971936226\n",
      "Epoch [7/15], Loss : 0.4294527492821217\n",
      "Epoch [8/15], Loss : 0.3498104492723942\n",
      "Epoch [9/15], Loss : 0.29040762688219546\n",
      "Epoch [10/15], Loss : 0.2406279271543026\n",
      "Pruning done.\n",
      "Epoch [11/15], Loss : 0.1925336010158062\n",
      "Epoch [12/15], Loss : 0.1523590096011758\n",
      "Epoch [13/15], Loss : 0.13485703682899475\n",
      "Epoch [14/15], Loss : 0.11096452654153109\n",
      "Epoch [15/15], Loss : 0.09422422910109163\n",
      "Pruning done.\n"
     ]
    }
   ],
   "source": [
    "train_pruned_model(model, device, train_loader, optimizer,criterion, epochs=15,prune_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b7df63",
   "metadata": {},
   "source": [
    "Printing the weights after weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60117254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned weights:\n",
      " Parameter containing:\n",
      "tensor([[[[ 0.0283, -0.0000,  0.0969,  ...,  0.2377,  0.2719,  0.2704],\n",
      "          [ 0.0937,  0.1755,  0.2025,  ...,  0.3112,  0.4571,  0.3884],\n",
      "          [ 0.0378,  0.0160,  0.1953,  ...,  0.1639,  0.3054,  0.2367],\n",
      "          ...,\n",
      "          [-0.0850, -0.2339, -0.2266,  ..., -0.2001, -0.1158, -0.0329],\n",
      "          [-0.1494, -0.1883, -0.2235,  ..., -0.1210, -0.0259, -0.0951],\n",
      "          [-0.0800, -0.0899, -0.1976,  ..., -0.1581, -0.1125, -0.0542]],\n",
      "\n",
      "         [[-0.0981, -0.0684, -0.1841,  ..., -0.0808, -0.1230, -0.0682],\n",
      "          [-0.1321, -0.1509, -0.1528,  ..., -0.1558, -0.2710, -0.1610],\n",
      "          [-0.1006, -0.1349, -0.1860,  ..., -0.0967, -0.1624, -0.1573],\n",
      "          ...,\n",
      "          [ 0.0394,  0.0785, -0.0386,  ...,  0.0206, -0.0891, -0.0199],\n",
      "          [ 0.0482,  0.1054,  0.0805,  ...,  0.1334,  0.0386,  0.0142],\n",
      "          [ 0.1483,  0.1180,  0.1499,  ...,  0.0794,  0.0826,  0.0219]],\n",
      "\n",
      "         [[ 0.0000,  0.1675,  0.0580,  ..., -0.0747, -0.1321, -0.1428],\n",
      "          [ 0.0280,  0.0315, -0.1391,  ..., -0.2018, -0.2928, -0.2896],\n",
      "          [ 0.1152,  0.0574, -0.0547,  ..., -0.0902, -0.1978, -0.2299],\n",
      "          ...,\n",
      "          [ 0.0435,  0.0667,  0.2717,  ...,  0.1304,  0.0424, -0.0292],\n",
      "          [ 0.0805,  0.2060,  0.1108,  ...,  0.1074,  0.1190,  0.0446],\n",
      "          [ 0.0139,  0.0605,  0.1064,  ...,  0.0673,  0.0178,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0452,  0.1171,  0.0928,  ..., -0.0280, -0.0406,  0.0513],\n",
      "          [ 0.0700, -0.0333, -0.0478,  ...,  0.1215,  0.0646, -0.0234],\n",
      "          [-0.0000, -0.0000, -0.0310,  ...,  0.0909,  0.0400, -0.0190],\n",
      "          ...,\n",
      "          [ 0.0000, -0.0999,  0.0261,  ..., -0.0671,  0.0000, -0.0313],\n",
      "          [ 0.0537,  0.0000, -0.0455,  ...,  0.0309,  0.0000, -0.0418],\n",
      "          [-0.0638, -0.0738,  0.0319,  ...,  0.0252,  0.0137, -0.0552]],\n",
      "\n",
      "         [[ 0.0682, -0.0188, -0.0509,  ...,  0.0232,  0.0000,  0.0982],\n",
      "          [-0.0117,  0.0550,  0.0661,  ..., -0.0269,  0.0889, -0.0448],\n",
      "          [ 0.0162,  0.0841,  0.0907,  ...,  0.0697,  0.1205,  0.0534],\n",
      "          ...,\n",
      "          [-0.1083, -0.0000,  0.0000,  ...,  0.0000,  0.0753,  0.0374],\n",
      "          [ 0.0899, -0.0600,  0.0923,  ..., -0.0632, -0.0931, -0.0000],\n",
      "          [ 0.0810,  0.0413,  0.0630,  ...,  0.0219, -0.0458, -0.1280]],\n",
      "\n",
      "         [[-0.0440, -0.0611,  0.0412,  ...,  0.1139, -0.0000,  0.0686],\n",
      "          [-0.0859, -0.0000,  0.0000,  ...,  0.1040,  0.0950, -0.0187],\n",
      "          [-0.0414,  0.0617,  0.1165,  ...,  0.1051,  0.1214, -0.0000],\n",
      "          ...,\n",
      "          [-0.0701, -0.0566, -0.0246,  ..., -0.0157, -0.0280,  0.0000],\n",
      "          [ 0.0156,  0.0432,  0.0240,  ..., -0.0803, -0.0843, -0.1272],\n",
      "          [ 0.0207, -0.0798, -0.0960,  ..., -0.0965,  0.0198, -0.0141]]],\n",
      "\n",
      "\n",
      "        [[[-0.0280, -0.0871,  0.0428,  ..., -0.0135,  0.0264,  0.0310],\n",
      "          [-0.0932, -0.0336,  0.0466,  ...,  0.0162,  0.0980,  0.0290],\n",
      "          [ 0.0260, -0.0742,  0.0349,  ...,  0.1388,  0.0421,  0.0688],\n",
      "          ...,\n",
      "          [-0.0150, -0.1265, -0.0255,  ..., -0.0564,  0.1303,  0.0698],\n",
      "          [-0.0136, -0.0466, -0.1138,  ..., -0.0591, -0.0410,  0.0528],\n",
      "          [-0.0123, -0.0000, -0.0000,  ..., -0.0443, -0.0675,  0.0419]],\n",
      "\n",
      "         [[-0.0720, -0.0480,  0.1170,  ...,  0.0652,  0.0205, -0.0109],\n",
      "          [-0.0158, -0.0356,  0.0117,  ...,  0.0305,  0.0448, -0.0252],\n",
      "          [-0.1123, -0.0753,  0.0118,  ...,  0.0615,  0.1056,  0.0670],\n",
      "          ...,\n",
      "          [-0.0673, -0.0707, -0.0389,  ...,  0.0279,  0.0900,  0.1648],\n",
      "          [-0.0141,  0.0204, -0.0514,  ...,  0.0386,  0.0130,  0.0106],\n",
      "          [-0.0425, -0.0195, -0.0625,  ...,  0.0285,  0.0000,  0.0884]],\n",
      "\n",
      "         [[-0.0212, -0.1077,  0.0350,  ...,  0.0833,  0.0351, -0.0194],\n",
      "          [-0.0251,  0.0184,  0.0251,  ...,  0.0665,  0.0938,  0.0000],\n",
      "          [-0.0108, -0.0514,  0.0340,  ...,  0.0479,  0.0768,  0.0751],\n",
      "          ...,\n",
      "          [-0.0613, -0.0726, -0.0747,  ...,  0.1084,  0.0325,  0.1281],\n",
      "          [-0.0232, -0.0835, -0.0184,  ..., -0.0862,  0.0638,  0.0750],\n",
      "          [ 0.0373,  0.0400,  0.0000,  ..., -0.0000,  0.0338, -0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0482, -0.1225, -0.1006,  ..., -0.0000,  0.0640,  0.0607],\n",
      "          [ 0.0298,  0.1242, -0.0132,  ...,  0.0736,  0.0000,  0.0790],\n",
      "          [ 0.0347,  0.0890,  0.1024,  ...,  0.0495,  0.0732,  0.0493],\n",
      "          ...,\n",
      "          [ 0.0596,  0.0812,  0.0397,  ...,  0.0156,  0.0616, -0.1431],\n",
      "          [ 0.0664,  0.0143,  0.0617,  ...,  0.0000, -0.1117, -0.0309],\n",
      "          [-0.0464,  0.0000, -0.0153,  ..., -0.0949, -0.1293, -0.0272]],\n",
      "\n",
      "         [[-0.1326, -0.0792, -0.0723,  ..., -0.0669,  0.0000,  0.1408],\n",
      "          [-0.0666,  0.0487, -0.0907,  ..., -0.0812,  0.0947, -0.0000],\n",
      "          [ 0.0304,  0.1082, -0.0588,  ..., -0.0379,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [-0.0345, -0.0429, -0.0510,  ...,  0.0425,  0.0829, -0.0796],\n",
      "          [ 0.0139,  0.0636,  0.0741,  ...,  0.0784,  0.0000, -0.1154],\n",
      "          [ 0.0114,  0.0401,  0.0289,  ..., -0.0258,  0.0668, -0.0442]],\n",
      "\n",
      "         [[-0.0352, -0.0384, -0.1187,  ..., -0.1729,  0.0610,  0.0416],\n",
      "          [ 0.0000, -0.0496, -0.0837,  ..., -0.0904,  0.0000,  0.1248],\n",
      "          [ 0.0309, -0.0658, -0.1543,  ...,  0.0000,  0.0595,  0.0702],\n",
      "          ...,\n",
      "          [ 0.0423, -0.0316, -0.0000,  ...,  0.2064,  0.0147,  0.0142],\n",
      "          [-0.0000,  0.0117,  0.1684,  ...,  0.1161, -0.0501, -0.0639],\n",
      "          [-0.0543,  0.1544,  0.2003,  ...,  0.0427, -0.0661,  0.0692]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0451, -0.0289,  0.1082,  ...,  0.0420, -0.0953, -0.0152],\n",
      "          [-0.0428, -0.0849,  0.0707,  ...,  0.0946,  0.0148, -0.0544],\n",
      "          [-0.0803, -0.0919,  0.0943,  ...,  0.0994, -0.0125,  0.0142],\n",
      "          ...,\n",
      "          [-0.0512, -0.0720,  0.1198,  ...,  0.1125,  0.0596, -0.0725],\n",
      "          [-0.0830,  0.0177,  0.0476,  ...,  0.1202,  0.0493,  0.0421],\n",
      "          [-0.0719,  0.0321,  0.0899,  ...,  0.0000,  0.0918, -0.0248]],\n",
      "\n",
      "         [[-0.0829, -0.1431, -0.0000,  ...,  0.0507,  0.0475,  0.0287],\n",
      "          [-0.1494, -0.1607, -0.0965,  ...,  0.0677,  0.1368, -0.0615],\n",
      "          [-0.1055, -0.1421, -0.0221,  ...,  0.1079,  0.0992, -0.0000],\n",
      "          ...,\n",
      "          [-0.1662, -0.0754,  0.0619,  ...,  0.0471,  0.1354,  0.0870],\n",
      "          [-0.1252, -0.1328, -0.0274,  ...,  0.0922,  0.1424, -0.0449],\n",
      "          [ 0.0000, -0.0769, -0.1053,  ..., -0.0000,  0.0288,  0.0373]],\n",
      "\n",
      "         [[-0.1269, -0.1753, -0.1556,  ...,  0.0914, -0.0000,  0.0000],\n",
      "          [-0.0181, -0.0922, -0.1298,  ...,  0.1035,  0.1236, -0.0000],\n",
      "          [-0.0837, -0.1744, -0.0000,  ...,  0.1611,  0.0192,  0.0393],\n",
      "          ...,\n",
      "          [ 0.0400, -0.0512,  0.0200,  ...,  0.1385,  0.1174, -0.0348],\n",
      "          [ 0.0570, -0.0232,  0.0233,  ...,  0.0447, -0.0000,  0.0190],\n",
      "          [-0.0487, -0.0658, -0.0496,  ...,  0.0134, -0.0424, -0.1066]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.1085,  0.1210,  ...,  0.0823,  0.0432,  0.0480],\n",
      "          [ 0.1572,  0.1480,  0.1477,  ...,  0.0752, -0.0304, -0.0873],\n",
      "          [ 0.0816,  0.0132,  0.0218,  ..., -0.0218, -0.0363, -0.0793],\n",
      "          ...,\n",
      "          [ 0.1155,  0.0449,  0.0336,  ..., -0.0376, -0.1553, -0.1039],\n",
      "          [ 0.1752, -0.0699, -0.1110,  ..., -0.0937, -0.1458, -0.0186],\n",
      "          [-0.1022, -0.1858, -0.1233,  ..., -0.0945, -0.1178, -0.1814]],\n",
      "\n",
      "         [[-0.0152,  0.0000,  0.1539,  ...,  0.0610, -0.0000,  0.0945],\n",
      "          [ 0.1227,  0.0846,  0.1020,  ...,  0.1017, -0.0200,  0.0618],\n",
      "          [ 0.0440,  0.0187, -0.0768,  ..., -0.0223, -0.1132, -0.0183],\n",
      "          ...,\n",
      "          [ 0.0321, -0.0209, -0.0000,  ..., -0.0000, -0.0765, -0.1334],\n",
      "          [ 0.0252, -0.0000,  0.0000,  ..., -0.0186, -0.1548, -0.0311],\n",
      "          [-0.0000, -0.2042, -0.0452,  ..., -0.0941, -0.0644,  0.0154]],\n",
      "\n",
      "         [[ 0.1096, -0.0284,  0.0463,  ...,  0.0509,  0.0371,  0.0624],\n",
      "          [ 0.0705,  0.1298, -0.0000,  ..., -0.0000,  0.0736, -0.0653],\n",
      "          [-0.0546, -0.0598, -0.1281,  ..., -0.0913, -0.0582, -0.0349],\n",
      "          ...,\n",
      "          [ 0.1171,  0.0114, -0.0282,  ..., -0.1170, -0.0998, -0.0207],\n",
      "          [ 0.0188, -0.0000, -0.0000,  ..., -0.0000,  0.0220,  0.0743],\n",
      "          [-0.0694, -0.1266, -0.0266,  ..., -0.0000,  0.0212,  0.0482]]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Pruned weights:\\n\", model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855e1be4",
   "metadata": {},
   "source": [
    "No.of Zero parameters after weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "194b76e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117203\n"
     ]
    }
   ],
   "source": [
    "after_pruning = count_zero_params(model)\n",
    "print(after_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f82d399",
   "metadata": {},
   "source": [
    "Evaluating the model and printing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70eca084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================AFTER WEIGHT PRUNING========================================\n",
      "Accuracy: 75 %\n",
      "Elapsed time = 31.1096 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device ='cpu'\n",
    "print(\"=====================================AFTER WEIGHT PRUNING========================================\")\n",
    "evaluate_model(model,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0739f5",
   "metadata": {},
   "source": [
    "Function to print the size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f2a0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model,path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print('Size (MB):', os.path.getsize(path)/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b6cbd",
   "metadata": {},
   "source": [
    "Printing the size of the model before quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12fb58b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================BEFORE QUANTIZATION========================================\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "Size of the model Before Dynamic quantization\n",
      "Size (MB): 44.830943\n"
     ]
    }
   ],
   "source": [
    "print(\"=====================================BEFORE QUANTIZATION========================================\")\n",
    "print(model)\n",
    "print('Size of the model Before Dynamic quantization')\n",
    "print_size_of_model(model,path=\"FinalTask11.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e352f",
   "metadata": {},
   "source": [
    "# Dynamic quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be1bf7",
   "metadata": {},
   "source": [
    "Doing dynamic quantization for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7d932db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dynamic_quantized = torch.quantization.quantize_dynamic(\n",
    "    model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2311ff8b",
   "metadata": {},
   "source": [
    "Printing the model and size of it after dynamic quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49a6205a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================DYNAMIC QUANTIZATION========================================\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "Size of the model After Dynamic quantization\n",
      "Size (MB): 44.816363\n"
     ]
    }
   ],
   "source": [
    "print(\"=====================================DYNAMIC QUANTIZATION========================================\")\n",
    "print(model_dynamic_quantized)\n",
    "print('Size of the model After Dynamic quantization')\n",
    "print_size_of_model(model_dynamic_quantized,path=\"FinalTask11_dynamic.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb773a",
   "metadata": {},
   "source": [
    "Evaluating and printing the accuracy of the model after dynamic quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "664c43fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================ACCURACY AFTER DYNAMIC QUANTIZATION=======================================\n",
      "Accuracy: 76 %\n",
      "Elapsed time = 26.0303 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device ='cpu'\n",
    "print(\"=====================================ACCURACY AFTER DYNAMIC QUANTIZATION=======================================\")\n",
    "evaluate_model(model_dynamic_quantized,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8dcaa",
   "metadata": {},
   "source": [
    "# Static Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0638638",
   "metadata": {},
   "source": [
    "Doing Static quantization for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7157b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.09044206887483597, zero_point=63, padding=(3, 3))\n",
      "  (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.2592632472515106, zero_point=69, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.12315140664577484, zero_point=75, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.1417912095785141, zero_point=42\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.22581148147583008, zero_point=70, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.09417446702718735, zero_point=75, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.15213394165039062, zero_point=38\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.18402738869190216, zero_point=65, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.07918445020914078, zero_point=65, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.10932731628417969, zero_point=63)\n",
      "        (1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12139192968606949, zero_point=64\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1019546389579773, zero_point=68, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.076265849173069, zero_point=68, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12142342329025269, zero_point=48\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.11357851326465607, zero_point=62, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.06931683421134949, zero_point=59, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.06480938196182251, zero_point=66)\n",
      "        (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.11905626207590103, zero_point=59\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08195914328098297, zero_point=55, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.12925401329994202, zero_point=53, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12642347812652588, zero_point=40\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.11347646266222, zero_point=58, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.18701983988285065, zero_point=66, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.1292582005262375, zero_point=64)\n",
      "        (1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.2698507308959961, zero_point=62\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.17942506074905396, zero_point=64, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.3428482413291931, zero_point=69, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.2981424927711487, zero_point=58\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.09044206887483597, zero_point=63, padding=(3, 3))\n",
      "  (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.2592632472515106, zero_point=69, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.12315140664577484, zero_point=75, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.1417912095785141, zero_point=42\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.22581148147583008, zero_point=70, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.09417446702718735, zero_point=75, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.15213394165039062, zero_point=38\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.18402738869190216, zero_point=65, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.07918445020914078, zero_point=65, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.10932731628417969, zero_point=63)\n",
      "        (1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12139192968606949, zero_point=64\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1019546389579773, zero_point=68, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.076265849173069, zero_point=68, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12142342329025269, zero_point=48\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.11357851326465607, zero_point=62, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.06931683421134949, zero_point=59, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.06480938196182251, zero_point=66)\n",
      "        (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.11905626207590103, zero_point=59\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08195914328098297, zero_point=55, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.12925401329994202, zero_point=53, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12642347812652588, zero_point=40\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.11347646266222, zero_point=58, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.18701983988285065, zero_point=66, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.1292582005262375, zero_point=64)\n",
      "        (1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.2698507308959961, zero_point=62\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.17942506074905396, zero_point=64, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.3428482413291931, zero_point=69, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.2981424927711487, zero_point=58\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_dynamic_quantized.eval()\n",
    "model_dynamic_quantized.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "static_quantized = torch.quantization.prepare(model_dynamic_quantized, inplace=True)\n",
    "print(static_quantized)\n",
    "with torch.no_grad():\n",
    "    for data, target in train_loader:\n",
    "        static_quantized(data)\n",
    "static_quantized = torch.quantization.convert(static_quantized, inplace=True)\n",
    "print(static_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76db68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "# save/load using scripted model\n",
    "# scripted = torch.jit.script(static_quantized)\n",
    "# Static = io.BytesIO()\n",
    "# torch.jit.save(scripted, Static)\n",
    "# print(scripted)\n",
    "# Save\n",
    "torch.jit.save(torch.jit.script(static_quantized), \"static_.pth\")\n",
    "# Load\n",
    "# mq = torch.jit.load(\"quant_model.pth\")\n",
    "# b.seek(0)\n",
    "# scripted_quantized = torch.jit.load(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b3b0be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_quantized_model(path):\n",
    "    print('Size (MB):', os.path.getsize(path)/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fa4fde",
   "metadata": {},
   "source": [
    "Printing the model and size of it after Static quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c59e399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model After Static quantization\n",
      "Size (MB): 11.429824\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model After Static quantization')\n",
    "print_size_of_quantized_model(path=\"static_.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12430c",
   "metadata": {},
   "source": [
    "Evaluating and finding the accuracy of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6663c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================ACCURACY AFTER STATIC QUANTIZATION=======================================\n",
      "Accuracy: 76 %\n",
      "Elapsed time = 9.9797 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device ='cpu'\n",
    "print(\"=====================================ACCURACY AFTER STATIC QUANTIZATION=======================================\")\n",
    "evaluate_model(static_quantized,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678eefcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
