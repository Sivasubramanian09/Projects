{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de0906f5",
   "metadata": {},
   "source": [
    "# **Task11**\n",
    "\n",
    "Use the code from: https://medium.com/@rekalantar/pytorch-tutorial-dynamic-weight-pruning-for-more-optimized-and-faster-neural-networks-7b337e47987b to do dynamic weight pruning. If the full dataset is too large use a suitable subset size.\n",
    "\n",
    "Use post-training static quantization as well as dynamic quantization as given in: https://pytorch.org/tutorials/recipes/quantization.html to generate a dynamic weight pruning+quantized model. Compare accuracy of the quantized model vs the non-quantized model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685d4d6",
   "metadata": {},
   "source": [
    "## Importing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4452bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchsummary\n",
    "from torchvision import models, datasets\n",
    "from timeit import default_timer as timer\n",
    "import torch.quantization as quant\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662dc937",
   "metadata": {},
   "source": [
    "Checking for device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5077eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3987cc",
   "metadata": {},
   "source": [
    "Loading the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3635cba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "# Load and subset the dataset\n",
    "full_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(full_dataset, batch_size=100, shuffle=True)\n",
    "# Load the test dataset\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7058d3a",
   "metadata": {},
   "source": [
    "# Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689283f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, input_channels, out_planes, stride= 1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, out_planes, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 =  nn.Conv2d(out_planes, out_planes, kernel_size=3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.downsample = downsample\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        # Notice the addition operation in both scenarios\n",
    "        x  = self.skip_add.add(x, identity)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_channels =3 ,num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.input_channels = 64\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.input_channels, kernel_size = 7, stride = 2, padding = 3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.input_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, layers[0], out=64,  stride= 1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], out=128, stride= 2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], out=256, stride= 2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], out=512, stride= 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def _make_layer(self, block, residual_blocks ,out, stride):\n",
    "        downsample = None\n",
    "        layers = []\n",
    "        if stride != 1 or self.input_channels != out:\n",
    "            downsample = nn.Sequential(nn.Conv2d(self.input_channels, out, kernel_size=1, stride= stride),\n",
    "                                       nn.BatchNorm2d(out))\n",
    "        layers.append(block(self.input_channels, out, stride, downsample))\n",
    "        self.input_channels = out\n",
    "        for _ in range(1, residual_blocks):\n",
    "            layers.append(block(self.input_channels, out))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input are quantized\n",
    "        x = self.quant(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dequant(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a68706",
   "metadata": {},
   "source": [
    "Calling the model ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f21b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f90fe8e",
   "metadata": {},
   "source": [
    "### Defining the optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98749e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664d4d9",
   "metadata": {},
   "source": [
    "### Function to count the zero parameters in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4a2d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zero_params(model):\n",
    "    zero_count = 0\n",
    "    for param in model.parameters():\n",
    "        zero_count += torch.sum(param == 0).item()\n",
    "    return zero_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2332a",
   "metadata": {},
   "source": [
    "Printing the No.of Zero parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ded48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n"
     ]
    }
   ],
   "source": [
    "before_pruning = count_zero_params(model)\n",
    "print(before_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bbafb",
   "metadata": {},
   "source": [
    "Printing the weights of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3c607aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights:\n",
      " Parameter containing:\n",
      "tensor([[[[-0.0524,  0.0089, -0.0540,  ..., -0.0436,  0.0112,  0.0015],\n",
      "          [ 0.0818,  0.0015, -0.0470,  ...,  0.0530,  0.0092, -0.0446],\n",
      "          [ 0.0023,  0.0574, -0.0408,  ..., -0.0574,  0.0068, -0.0247],\n",
      "          ...,\n",
      "          [-0.0500, -0.0031,  0.0059,  ...,  0.0519,  0.0768,  0.0786],\n",
      "          [ 0.0148,  0.0448, -0.0210,  ..., -0.0606, -0.0476,  0.0415],\n",
      "          [ 0.0300, -0.0013,  0.0273,  ..., -0.0186,  0.0618,  0.0060]],\n",
      "\n",
      "         [[-0.0252,  0.0551,  0.0318,  ..., -0.0363,  0.0460, -0.0005],\n",
      "          [ 0.0265, -0.0037, -0.0777,  ..., -0.0225,  0.0480,  0.0665],\n",
      "          [-0.0330, -0.0513,  0.0290,  ..., -0.0266, -0.0374, -0.0117],\n",
      "          ...,\n",
      "          [-0.0200,  0.0319,  0.0057,  ...,  0.0118, -0.0097,  0.0103],\n",
      "          [-0.0616, -0.0073, -0.0560,  ...,  0.0346, -0.0388, -0.0264],\n",
      "          [-0.0190, -0.0510,  0.0240,  ...,  0.0084, -0.0357, -0.0620]],\n",
      "\n",
      "         [[-0.0458, -0.0320, -0.0287,  ..., -0.0085, -0.0529, -0.0751],\n",
      "          [-0.0556,  0.0448, -0.0771,  ...,  0.0737, -0.0124,  0.0450],\n",
      "          [ 0.0212,  0.0697, -0.0065,  ..., -0.0540,  0.0379, -0.0388],\n",
      "          ...,\n",
      "          [ 0.0279, -0.0223,  0.0349,  ..., -0.0385,  0.0775, -0.0058],\n",
      "          [-0.0586,  0.0110, -0.0203,  ...,  0.0438,  0.0323,  0.0547],\n",
      "          [-0.0661, -0.0667,  0.0145,  ...,  0.0529, -0.0600,  0.0319]]],\n",
      "\n",
      "\n",
      "        [[[-0.0406, -0.0682, -0.0377,  ...,  0.0557,  0.0486, -0.0676],\n",
      "          [ 0.0053,  0.0555, -0.0421,  ...,  0.0790,  0.0580, -0.0520],\n",
      "          [-0.0557, -0.0177,  0.0071,  ..., -0.0720,  0.0064, -0.0550],\n",
      "          ...,\n",
      "          [ 0.0088, -0.0775,  0.0577,  ..., -0.0494,  0.0231, -0.0735],\n",
      "          [-0.0286,  0.0736, -0.0816,  ...,  0.0697, -0.0825, -0.0323],\n",
      "          [-0.0340,  0.0762, -0.0433,  ..., -0.0368,  0.0645,  0.0396]],\n",
      "\n",
      "         [[ 0.0654,  0.0189, -0.0566,  ..., -0.0194, -0.0390,  0.0284],\n",
      "          [-0.0214, -0.0669,  0.0229,  ...,  0.0628,  0.0747, -0.0318],\n",
      "          [ 0.0728,  0.0147, -0.0186,  ..., -0.0320, -0.0715,  0.0434],\n",
      "          ...,\n",
      "          [ 0.0514,  0.0498, -0.0760,  ...,  0.0117, -0.0556, -0.0084],\n",
      "          [-0.0647, -0.0725, -0.0605,  ...,  0.0187,  0.0642, -0.0370],\n",
      "          [ 0.0539, -0.0382, -0.0258,  ...,  0.0042,  0.0553,  0.0272]],\n",
      "\n",
      "         [[ 0.0744, -0.0631, -0.0131,  ...,  0.0616, -0.0737, -0.0424],\n",
      "          [-0.0012, -0.0377,  0.0612,  ..., -0.0740, -0.0574,  0.0316],\n",
      "          [ 0.0429,  0.0525, -0.0317,  ...,  0.0287,  0.0735, -0.0487],\n",
      "          ...,\n",
      "          [ 0.0271,  0.0284, -0.0410,  ..., -0.0011, -0.0524,  0.0168],\n",
      "          [-0.0313, -0.0110,  0.0495,  ...,  0.0106, -0.0458,  0.0510],\n",
      "          [ 0.0664, -0.0167,  0.0308,  ...,  0.0611,  0.0422, -0.0065]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0343, -0.0530, -0.0420,  ..., -0.0558, -0.0822, -0.0753],\n",
      "          [ 0.0209,  0.0562,  0.0475,  ...,  0.0487, -0.0591,  0.0523],\n",
      "          [ 0.0421,  0.0509,  0.0297,  ...,  0.0476,  0.0172,  0.0249],\n",
      "          ...,\n",
      "          [ 0.0716,  0.0051,  0.0670,  ..., -0.0679, -0.0637, -0.0164],\n",
      "          [-0.0734, -0.0752, -0.0169,  ..., -0.0244,  0.0640, -0.0104],\n",
      "          [-0.0520, -0.0181, -0.0266,  ..., -0.0228, -0.0137,  0.0412]],\n",
      "\n",
      "         [[-0.0456,  0.0681, -0.0685,  ..., -0.0310,  0.0598,  0.0611],\n",
      "          [ 0.0621,  0.0820,  0.0205,  ...,  0.0465,  0.0467,  0.0767],\n",
      "          [ 0.0176, -0.0357, -0.0281,  ..., -0.0666,  0.0415,  0.0662],\n",
      "          ...,\n",
      "          [ 0.0194, -0.0628,  0.0409,  ...,  0.0480,  0.0343, -0.0481],\n",
      "          [-0.0443, -0.0763,  0.0362,  ..., -0.0666, -0.0674, -0.0362],\n",
      "          [ 0.0569, -0.0038, -0.0644,  ...,  0.0156, -0.0062, -0.0030]],\n",
      "\n",
      "         [[ 0.0213, -0.0446,  0.0034,  ...,  0.0298,  0.0522,  0.0694],\n",
      "          [ 0.0688,  0.0538, -0.0374,  ..., -0.0155,  0.0151,  0.0677],\n",
      "          [ 0.0782, -0.0304, -0.0255,  ...,  0.0136,  0.0437,  0.0432],\n",
      "          ...,\n",
      "          [ 0.0642,  0.0496,  0.0067,  ...,  0.0702,  0.0555,  0.0674],\n",
      "          [-0.0673, -0.0005, -0.0448,  ..., -0.0642, -0.0018,  0.0421],\n",
      "          [-0.0237, -0.0329,  0.0819,  ...,  0.0172,  0.0309, -0.0528]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0253, -0.0805, -0.0334,  ...,  0.0095,  0.0469, -0.0469],\n",
      "          [-0.0677,  0.0062, -0.0090,  ...,  0.0517,  0.0595,  0.0287],\n",
      "          [-0.0012, -0.0807, -0.0434,  ...,  0.0076, -0.0512,  0.0710],\n",
      "          ...,\n",
      "          [-0.0416, -0.0710,  0.0317,  ..., -0.0809, -0.0302,  0.0144],\n",
      "          [ 0.0459, -0.0195, -0.0763,  ..., -0.0799, -0.0083,  0.0303],\n",
      "          [-0.0118,  0.0536, -0.0332,  ...,  0.0719,  0.0566, -0.0096]],\n",
      "\n",
      "         [[-0.0577, -0.0477,  0.0061,  ..., -0.0432,  0.0679,  0.0098],\n",
      "          [-0.0464, -0.0699,  0.0537,  ..., -0.0494, -0.0195,  0.0141],\n",
      "          [ 0.0413,  0.0403, -0.0279,  ..., -0.0017, -0.0798, -0.0565],\n",
      "          ...,\n",
      "          [-0.0311, -0.0546, -0.0208,  ..., -0.0652,  0.0310, -0.0225],\n",
      "          [-0.0628, -0.0396, -0.0492,  ..., -0.0672,  0.0450,  0.0404],\n",
      "          [ 0.0695, -0.0611, -0.0188,  ...,  0.0463, -0.0804, -0.0543]],\n",
      "\n",
      "         [[ 0.0668, -0.0722,  0.0133,  ...,  0.0211, -0.0167, -0.0604],\n",
      "          [ 0.0423, -0.0101,  0.0651,  ..., -0.0458, -0.0164, -0.0699],\n",
      "          [ 0.0010, -0.0658,  0.0232,  ...,  0.0774, -0.0344, -0.0643],\n",
      "          ...,\n",
      "          [-0.0583, -0.0500, -0.0815,  ..., -0.0200, -0.0477,  0.0683],\n",
      "          [ 0.0222,  0.0313, -0.0085,  ..., -0.0129, -0.0614,  0.0184],\n",
      "          [ 0.0315,  0.0313,  0.0324,  ..., -0.0359, -0.0642,  0.0325]]],\n",
      "\n",
      "\n",
      "        [[[-0.0279, -0.0367, -0.0228,  ...,  0.0401,  0.0614, -0.0094],\n",
      "          [-0.0477, -0.0073,  0.0813,  ...,  0.0487, -0.0374, -0.0635],\n",
      "          [-0.0399, -0.0690,  0.0654,  ...,  0.0427, -0.0606, -0.0577],\n",
      "          ...,\n",
      "          [ 0.0650, -0.0188, -0.0470,  ..., -0.0050, -0.0390,  0.0716],\n",
      "          [ 0.0363,  0.0348, -0.0812,  ..., -0.0022,  0.0699,  0.0754],\n",
      "          [-0.0101, -0.0262,  0.0169,  ...,  0.0649, -0.0794, -0.0691]],\n",
      "\n",
      "         [[-0.0041, -0.0236, -0.0017,  ...,  0.0026, -0.0093, -0.0122],\n",
      "          [ 0.0690, -0.0425,  0.0180,  ...,  0.0742, -0.0808, -0.0317],\n",
      "          [-0.0044,  0.0569, -0.0682,  ...,  0.0345,  0.0605,  0.0199],\n",
      "          ...,\n",
      "          [ 0.0475, -0.0218, -0.0206,  ..., -0.0278,  0.0269, -0.0038],\n",
      "          [ 0.0032,  0.0203, -0.0160,  ..., -0.0043,  0.0744, -0.0098],\n",
      "          [ 0.0162, -0.0300, -0.0822,  ..., -0.0564, -0.0128, -0.0493]],\n",
      "\n",
      "         [[ 0.0454,  0.0530, -0.0431,  ..., -0.0765,  0.0623,  0.0760],\n",
      "          [ 0.0740,  0.0090, -0.0689,  ..., -0.0336,  0.0769, -0.0721],\n",
      "          [-0.0120, -0.0313,  0.0251,  ...,  0.0404, -0.0287,  0.0425],\n",
      "          ...,\n",
      "          [-0.0716,  0.0418, -0.0346,  ..., -0.0586, -0.0348, -0.0450],\n",
      "          [ 0.0009, -0.0103, -0.0512,  ..., -0.0802, -0.0331, -0.0251],\n",
      "          [-0.0501, -0.0198, -0.0619,  ..., -0.0280, -0.0446, -0.0553]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0081, -0.0807,  0.0612,  ..., -0.0403, -0.0022, -0.0353],\n",
      "          [ 0.0230, -0.0564,  0.0551,  ...,  0.0689, -0.0354,  0.0104],\n",
      "          [-0.0359,  0.0476, -0.0199,  ...,  0.0767,  0.0650,  0.0099],\n",
      "          ...,\n",
      "          [-0.0491, -0.0817,  0.0630,  ..., -0.0107, -0.0677, -0.0582],\n",
      "          [ 0.0199,  0.0690,  0.0370,  ..., -0.0777, -0.0437,  0.0367],\n",
      "          [ 0.0043, -0.0469,  0.0643,  ..., -0.0753,  0.0250, -0.0679]],\n",
      "\n",
      "         [[-0.0311,  0.0617,  0.0371,  ..., -0.0290,  0.0500, -0.0261],\n",
      "          [ 0.0581, -0.0565, -0.0049,  ..., -0.0230,  0.0372,  0.0160],\n",
      "          [ 0.0423, -0.0702,  0.0306,  ..., -0.0529, -0.0443,  0.0485],\n",
      "          ...,\n",
      "          [-0.0609, -0.0556,  0.0733,  ..., -0.0060, -0.0068, -0.0115],\n",
      "          [ 0.0472,  0.0646, -0.0161,  ..., -0.0461,  0.0176,  0.0667],\n",
      "          [ 0.0256,  0.0354, -0.0238,  ..., -0.0736, -0.0171, -0.0613]],\n",
      "\n",
      "         [[ 0.0591,  0.0494, -0.0388,  ..., -0.0707,  0.0338, -0.0755],\n",
      "          [ 0.0233, -0.0694, -0.0682,  ...,  0.0705, -0.0511, -0.0420],\n",
      "          [ 0.0538,  0.0558, -0.0583,  ...,  0.0203,  0.0253,  0.0323],\n",
      "          ...,\n",
      "          [ 0.0037, -0.0629,  0.0195,  ..., -0.0711,  0.0536,  0.0547],\n",
      "          [-0.0387,  0.0596,  0.0032,  ...,  0.0024, -0.0080,  0.0793],\n",
      "          [ 0.0578,  0.0015, -0.0361,  ...,  0.0563,  0.0039,  0.0375]]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original weights:\\n\", model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22494fdd",
   "metadata": {},
   "source": [
    "Function to train the model and to do weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e71d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def prune_model(model, pruning_rate=0.1):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "            \n",
    "            # Applying unstructured L1 norm pruning\n",
    "            prune.l1_unstructured(module, name='weight', amount=pruning_rate)\n",
    "            \n",
    "            prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b093db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pruned_model(model, device, train_loader, optimizer, criterion,epochs,prune_epoch):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss : {running_loss / len(train_loader)}')       \n",
    "        \n",
    "        if (epoch+1) % prune_epoch == 0:\n",
    "            prune_model(model, pruning_rate=0.1)\n",
    "            print('Pruning done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc649709",
   "metadata": {},
   "source": [
    "## Calling the function train_model to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "324a47ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss : 1.4877073529958724\n",
      "Epoch [2/15], Loss : 1.0292752691507339\n",
      "Epoch [3/15], Loss : 0.8216779981851577\n",
      "Epoch [4/15], Loss : 0.6850200694203377\n",
      "Epoch [5/15], Loss : 0.5741130374073983\n",
      "Pruning done.\n",
      "Epoch [6/15], Loss : 0.48218989551067354\n",
      "Epoch [7/15], Loss : 0.4089094673991203\n",
      "Epoch [8/15], Loss : 0.33029090958833696\n",
      "Epoch [9/15], Loss : 0.27293209539353847\n",
      "Epoch [10/15], Loss : 0.220408936470747\n",
      "Pruning done.\n",
      "Epoch [11/15], Loss : 0.1782695506811142\n",
      "Epoch [12/15], Loss : 0.14709078270941972\n",
      "Epoch [13/15], Loss : 0.12446953675895929\n",
      "Epoch [14/15], Loss : 0.10481965002603828\n",
      "Epoch [15/15], Loss : 0.08701379926875234\n",
      "Pruning done.\n"
     ]
    }
   ],
   "source": [
    "train_pruned_model(model, device, train_loader, optimizer,criterion, epochs=15,prune_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335d26a",
   "metadata": {},
   "source": [
    "Printing the weights after weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7609e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned weights:\n",
      " Parameter containing:\n",
      "tensor([[[[ 0.0260,  0.0481, -0.0000,  ...,  0.0304,  0.0649, -0.0310],\n",
      "          [ 0.0676, -0.0616, -0.1236,  ...,  0.0000, -0.0000, -0.0704],\n",
      "          [-0.0378, -0.0186, -0.1223,  ..., -0.1802, -0.0868, -0.1080],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0372,  0.0431,  ...,  0.1583,  0.1463,  0.1324],\n",
      "          [ 0.0388,  0.0568, -0.0159,  ..., -0.0628, -0.0247,  0.0224],\n",
      "          [ 0.1341,  0.1095,  0.1253,  ...,  0.0631,  0.1341,  0.0000]],\n",
      "\n",
      "         [[ 0.1054,  0.1132,  0.1097,  ...,  0.0785,  0.1831,  0.0746],\n",
      "          [ 0.0205, -0.0969, -0.1763,  ..., -0.0875,  0.0521,  0.0853],\n",
      "          [-0.0811, -0.1372, -0.0440,  ..., -0.1647, -0.1625, -0.1277],\n",
      "          ...,\n",
      "          [-0.0765, -0.0339, -0.0243,  ...,  0.0388, -0.0726, -0.0414],\n",
      "          [-0.1704, -0.1358, -0.1861,  ..., -0.1241, -0.1798, -0.1472],\n",
      "          [-0.0602, -0.1049, -0.0178,  ..., -0.0941, -0.1335, -0.1664]],\n",
      "\n",
      "         [[-0.0233, -0.0928, -0.0514,  ..., -0.0000, -0.0162, -0.0797],\n",
      "          [-0.1109, -0.1066, -0.2211,  ..., -0.0000, -0.0200,  0.0789],\n",
      "          [ 0.0000,  0.0000, -0.0630,  ..., -0.1520, -0.0285, -0.0802],\n",
      "          ...,\n",
      "          [ 0.1164,  0.0926,  0.1702,  ...,  0.1577,  0.1815,  0.1098],\n",
      "          [-0.0447,  0.0268, -0.0225,  ...,  0.0306,  0.0236,  0.0785],\n",
      "          [-0.0212, -0.0306,  0.0476,  ...,  0.0530, -0.0510,  0.0439]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0136, -0.0000, -0.0000,  ...,  0.0107,  0.0475, -0.0000],\n",
      "          [ 0.0812,  0.1022, -0.0554,  ...,  0.0607,  0.0860,  0.0383],\n",
      "          [ 0.0677,  0.0156, -0.0211,  ..., -0.0794,  0.0000,  0.0442],\n",
      "          ...,\n",
      "          [-0.0247, -0.1848, -0.0835,  ..., -0.1670,  0.0904,  0.0754],\n",
      "          [-0.0860,  0.0159, -0.1492,  ...,  0.0695,  0.0482,  0.1601],\n",
      "          [-0.0378,  0.0595, -0.0683,  ...,  0.0614,  0.1675,  0.2103]],\n",
      "\n",
      "         [[ 0.0493,  0.0260, -0.0429,  ..., -0.0985, -0.0873,  0.0422],\n",
      "          [-0.0000, -0.0723, -0.0000,  ...,  0.0171,  0.0773,  0.0252],\n",
      "          [ 0.1206,  0.0000, -0.0418,  ..., -0.0609, -0.0845,  0.1103],\n",
      "          ...,\n",
      "          [ 0.0000, -0.0573, -0.1999,  ..., -0.1191, -0.0119,  0.1092],\n",
      "          [-0.1082, -0.1100, -0.1060,  ..., -0.0000,  0.1540,  0.0952],\n",
      "          [ 0.0717, -0.0330, -0.0438,  ...,  0.0679,  0.1146,  0.1407]],\n",
      "\n",
      "         [[ 0.0339, -0.0593,  0.0201,  ...,  0.0462, -0.0741, -0.0000],\n",
      "          [-0.0482, -0.0641,  0.0548,  ..., -0.0462,  0.0000,  0.1064],\n",
      "          [ 0.0385,  0.0393, -0.0251,  ...,  0.0558,  0.1063,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0329,  0.0202, -0.0496,  ..., -0.0360, -0.0125,  0.0728],\n",
      "          [-0.0000,  0.0583,  0.1270,  ...,  0.0546,  0.0186,  0.1017],\n",
      "          [ 0.1711,  0.1120,  0.1377,  ...,  0.1712,  0.0751,  0.0414]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0826, -0.0587,  ..., -0.1209, -0.1823, -0.1503],\n",
      "          [ 0.0272,  0.1121,  0.1715,  ...,  0.1460, -0.0136,  0.1067],\n",
      "          [ 0.0784,  0.1849,  0.1838,  ...,  0.2508,  0.1224,  0.0923],\n",
      "          ...,\n",
      "          [ 0.0484, -0.0305,  0.0000,  ..., -0.1418, -0.1569, -0.0995],\n",
      "          [-0.0917, -0.1171, -0.0713,  ..., -0.1015,  0.0199, -0.0222],\n",
      "          [-0.0618, -0.0224, -0.0279,  ...,  0.0000, -0.0209,  0.0164]],\n",
      "\n",
      "         [[-0.0902,  0.0268, -0.1201,  ..., -0.1600, -0.0654, -0.0487],\n",
      "          [ 0.0249,  0.0980,  0.0836,  ...,  0.0686,  0.0431,  0.0798],\n",
      "          [-0.0113,  0.0558,  0.0938,  ...,  0.1020,  0.1226,  0.1035],\n",
      "          ...,\n",
      "          [ 0.0000, -0.0712, -0.0000,  ..., -0.0000, -0.0322, -0.0918],\n",
      "          [-0.0653, -0.1195, -0.0169,  ..., -0.1496, -0.1058, -0.0451],\n",
      "          [ 0.0190, -0.0418, -0.0886,  ...,  0.0000, -0.0447, -0.0600]],\n",
      "\n",
      "         [[-0.0548, -0.1289, -0.1135,  ..., -0.1535, -0.1030, -0.0556],\n",
      "          [ 0.0261,  0.0479, -0.0131,  ..., -0.0345,  0.0000,  0.0801],\n",
      "          [ 0.0676,  0.0687,  0.0854,  ...,  0.1713,  0.1336,  0.1166],\n",
      "          ...,\n",
      "          [ 0.1196,  0.1253,  0.0358,  ...,  0.0945,  0.0731,  0.1186],\n",
      "          [-0.0110,  0.0361, -0.0330,  ..., -0.0967,  0.0219,  0.0931],\n",
      "          [-0.0339, -0.0505,  0.0647,  ...,  0.0000,  0.0000, -0.1040]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1510, -0.1311, -0.0628,  ..., -0.2120, -0.0272,  0.0119],\n",
      "          [ 0.1263, -0.2187, -0.1174,  ..., -0.2571,  0.0000,  0.1084],\n",
      "          [ 0.2581, -0.3634, -0.1135,  ..., -0.3051, -0.0590,  0.1327],\n",
      "          ...,\n",
      "          [ 0.0820, -0.1545, -0.2028,  ..., -0.2244, -0.1695,  0.0560],\n",
      "          [ 0.0282, -0.0773, -0.2754,  ..., -0.1172, -0.1648,  0.0349],\n",
      "          [ 0.0726,  0.0830, -0.1564,  ...,  0.0706, -0.0572,  0.1224]],\n",
      "\n",
      "         [[ 0.0683, -0.1934, -0.0523,  ..., -0.1806,  0.0404,  0.0633],\n",
      "          [ 0.1300, -0.3884, -0.1244,  ..., -0.3142, -0.0595,  0.0635],\n",
      "          [ 0.3091, -0.2696, -0.1325,  ..., -0.2879, -0.0819,  0.0158],\n",
      "          ...,\n",
      "          [ 0.1762, -0.1228, -0.2424,  ..., -0.2200, -0.0778,  0.0487],\n",
      "          [-0.0171, -0.0920, -0.2050,  ..., -0.1024, -0.0742,  0.0849],\n",
      "          [ 0.1826, -0.0381, -0.0863,  ...,  0.0765, -0.1774,  0.0925]],\n",
      "\n",
      "         [[ 0.1202, -0.1936, -0.0165,  ..., -0.0644,  0.0345, -0.0000],\n",
      "          [ 0.1576, -0.2026, -0.0458,  ..., -0.2384,  0.0507, -0.0000],\n",
      "          [ 0.2409, -0.2557, -0.0496,  ..., -0.2137,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0939, -0.0751, -0.2823,  ..., -0.1953, -0.1073,  0.1045],\n",
      "          [ 0.0124,  0.0118, -0.1168,  ..., -0.0447, -0.1284,  0.0615],\n",
      "          [ 0.0000, -0.0854, -0.1114,  ..., -0.0746, -0.1673,  0.1546]]],\n",
      "\n",
      "\n",
      "        [[[-0.0219, -0.0229,  0.0000,  ...,  0.0769,  0.1249,  0.0000],\n",
      "          [-0.0315,  0.0442,  0.1153,  ...,  0.0894,  0.0439, -0.0469],\n",
      "          [-0.0000,  0.0000,  0.1134,  ...,  0.0614, -0.0122, -0.0564],\n",
      "          ...,\n",
      "          [ 0.1128,  0.0327,  0.0108,  ..., -0.0000, -0.0507,  0.0485],\n",
      "          [ 0.0972,  0.0963, -0.0222,  ..., -0.0169,  0.0484,  0.0507],\n",
      "          [ 0.0408, -0.0323,  0.0353,  ...,  0.1005, -0.0455, -0.0302]],\n",
      "\n",
      "         [[ 0.0421, -0.0000,  0.0163,  ..., -0.0723, -0.0633, -0.0670],\n",
      "          [ 0.1218, -0.0129, -0.0000,  ..., -0.0255, -0.1309, -0.1130],\n",
      "          [ 0.0649,  0.0801, -0.1101,  ..., -0.0649, -0.0134, -0.0757],\n",
      "          ...,\n",
      "          [ 0.0771, -0.0407, -0.0571,  ..., -0.0954, -0.0393, -0.0753],\n",
      "          [ 0.0000, -0.0000, -0.0770,  ..., -0.0990,  0.0107, -0.0538],\n",
      "          [ 0.0112, -0.1444, -0.1880,  ..., -0.0805,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0685,  0.0837, -0.0000,  ..., -0.1073,  0.0592,  0.0845],\n",
      "          [ 0.1286,  0.0562, -0.0715,  ..., -0.0538,  0.1056, -0.0793],\n",
      "          [ 0.0719,  0.0166,  0.0000,  ...,  0.0000, -0.0148,  0.0166],\n",
      "          ...,\n",
      "          [ 0.0107,  0.0726, -0.0220,  ..., -0.0423, -0.0235, -0.0517],\n",
      "          [ 0.0405, -0.0112, -0.0653,  ..., -0.1042, -0.0331, -0.0211],\n",
      "          [-0.0398, -0.0987, -0.1263,  ..., -0.0000,  0.0000,  0.0144]]],\n",
      "\n",
      "\n",
      "        [[[-0.0606, -0.1043,  0.0617,  ..., -0.0836, -0.0312, -0.0000],\n",
      "          [-0.0465,  0.0000,  0.0000,  ..., -0.0845, -0.0439,  0.0735],\n",
      "          [ 0.0000,  0.0406, -0.2452,  ...,  0.3159,  0.3503,  0.0526],\n",
      "          ...,\n",
      "          [-0.1090, -0.0595,  0.2059,  ..., -0.3728, -0.5267, -0.1338],\n",
      "          [ 0.0384,  0.1524, -0.0402,  ..., -0.2226,  0.0442,  0.1911],\n",
      "          [ 0.0305, -0.0715, -0.0576,  ...,  0.1104,  0.1304, -0.1423]],\n",
      "\n",
      "         [[-0.0719,  0.0856,  0.0988,  ..., -0.0487,  0.0000, -0.0531],\n",
      "          [ 0.0144,  0.0108, -0.0175,  ..., -0.1965,  0.0210,  0.0852],\n",
      "          [ 0.1761,  0.0151, -0.1049,  ...,  0.2143,  0.2822,  0.1600],\n",
      "          ...,\n",
      "          [-0.0628,  0.0202,  0.2342,  ..., -0.3487, -0.4060, -0.0559],\n",
      "          [ 0.0985,  0.1354, -0.1460,  ..., -0.2289,  0.1302,  0.2494],\n",
      "          [ 0.0133, -0.0361, -0.1735,  ...,  0.0849,  0.0862, -0.1144]],\n",
      "\n",
      "         [[-0.0249,  0.0591,  0.0600,  ..., -0.1312, -0.0475, -0.1227],\n",
      "          [-0.0713, -0.0582, -0.0858,  ..., -0.2060, -0.1215, -0.0000],\n",
      "          [ 0.0874,  0.0414, -0.2697,  ...,  0.0903,  0.2465,  0.1387],\n",
      "          ...,\n",
      "          [-0.0261,  0.0439,  0.1948,  ..., -0.3669, -0.2445,  0.1059],\n",
      "          [-0.0209,  0.1627, -0.0756,  ..., -0.1241,  0.1486,  0.2914],\n",
      "          [ 0.0138, -0.0463, -0.1275,  ...,  0.2093,  0.0931, -0.0666]]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Pruned weights:\\n\", model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e72fe",
   "metadata": {},
   "source": [
    "No.of Zero parameters after weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46699ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117203\n"
     ]
    }
   ],
   "source": [
    "after_pruning = count_zero_params(model)\n",
    "print(after_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a0731",
   "metadata": {},
   "source": [
    "Function to Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16e8e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def evaluate_model(model,device):\n",
    "    model = model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            st = time.time()\n",
    "            outputs = model(images)\n",
    "            et = time.time()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct // total} %')\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f35215",
   "metadata": {},
   "source": [
    "Evaluating the model and printing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a72998ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================AFTER WEIGHT PRUNING========================================\n",
      "Accuracy: 75 %\n",
      "Elapsed time = 62.7477 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device ='cpu'\n",
    "print(\"=====================================AFTER WEIGHT PRUNING========================================\")\n",
    "evaluate_model(model,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6fe60b",
   "metadata": {},
   "source": [
    "Function to print the size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b92eec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model,path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print('Size (MB):', os.path.getsize(path)/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03240ece",
   "metadata": {},
   "source": [
    "Printing the size of the model before quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be100786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================BEFORE QUANTIZATION========================================\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "Size of the model Before Dynamic quantization\n",
      "Size (MB): 44.831076\n"
     ]
    }
   ],
   "source": [
    "print(\"=====================================BEFORE QUANTIZATION========================================\")\n",
    "print(model)\n",
    "print('Size of the model Before Dynamic quantization')\n",
    "print_size_of_model(model,path=\"FinalTask11.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ca544",
   "metadata": {},
   "source": [
    "# Dynamic quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9949c611",
   "metadata": {},
   "source": [
    "Doing dynamic quantization for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c1f8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dynamic_quantized = torch.quantization.quantize_dynamic(\n",
    "    model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec8cadc",
   "metadata": {},
   "source": [
    "Printing the model and size of it after dynamic quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0797e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================DYNAMIC QUANTIZATION========================================\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "Size of the model After Dynamic quantization\n",
      "Size (MB): 44.816486\n"
     ]
    }
   ],
   "source": [
    "print(\"=====================================DYNAMIC QUANTIZATION========================================\")\n",
    "print(model_dynamic_quantized)\n",
    "print('Size of the model After Dynamic quantization')\n",
    "print_size_of_model(model_dynamic_quantized,path=\"FinalTask11_dynamic.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9447fde",
   "metadata": {},
   "source": [
    "# Static Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518750cb",
   "metadata": {},
   "source": [
    "Doing Static quantization for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec8d7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dynamic_quantized.eval()\n",
    "model_dynamic_quantized.qconfig = torch.quantization.get_default_qconfig('fbgemm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5283dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(\n",
      "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (bn1): BatchNorm2d(\n",
      "    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (relu): ReLU(\n",
      "    inplace=True\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(\n",
      "          64, 128, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "        (1): BatchNorm2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(\n",
      "          128, 256, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "        (1): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "        (1): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "static_quantized = torch.quantization.prepare(model_dynamic_quantized, inplace=True)\n",
    "print(static_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92df40d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data, target in train_loader:\n",
    "        static_quantized(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52d12ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.0864262655377388, zero_point=63, padding=(3, 3))\n",
      "  (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.25623172521591187, zero_point=68, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10178610682487488, zero_point=71, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.13635751605033875, zero_point=42\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.24254532158374786, zero_point=71, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.09545330703258514, zero_point=73, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.13593928515911102, zero_point=41\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.192416250705719, zero_point=66, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.07817163318395615, zero_point=66, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.10868830978870392, zero_point=65)\n",
      "        (1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12522433698177338, zero_point=64\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10712841153144836, zero_point=68, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.07550304383039474, zero_point=71, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.11741483956575394, zero_point=48\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.11188741773366928, zero_point=61, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08438315242528915, zero_point=62, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.06697864830493927, zero_point=62)\n",
      "        (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.13268494606018066, zero_point=59\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.10049057006835938, zero_point=55, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.16349759697914124, zero_point=60, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.15677984058856964, zero_point=47\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.12882183492183685, zero_point=58, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.19198670983314514, zero_point=66, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.12725374102592468, zero_point=65)\n",
      "        (1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.28871047496795654, zero_point=61\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.18511879444122314, zero_point=62, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.3536423444747925, zero_point=70, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.3507896363735199, zero_point=59\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "static_quantized = torch.quantization.convert(static_quantized, inplace=True)\n",
    "print(static_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "956e8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(torch.jit.script(static_quantized), \"static_.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99b42708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_quantized_model(path):\n",
    "    print('Size (MB):', os.path.getsize(path)/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac04d0b",
   "metadata": {},
   "source": [
    "Printing the model and size of it after Static quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f9503bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model After Static quantization\n",
      "Size (MB): 11.429824\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model After Static quantization')\n",
    "print_size_of_quantized_model(path=\"static_.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3be831",
   "metadata": {},
   "source": [
    "Evaluating and finding the accuracy of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0aebaccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================ACCURACY AFTER STATIC QUANTIZATION=======================================\n",
      "Accuracy: 75 %\n",
      "Elapsed time = 10.3590 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device ='cpu'\n",
    "print(\"=====================================ACCURACY AFTER STATIC QUANTIZATION=======================================\")\n",
    "evaluate_model(static_quantized,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb9335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
