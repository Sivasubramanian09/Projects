{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea2f822",
   "metadata": {},
   "source": [
    "# **Task11**\n",
    "\n",
    "Use the code from: https://medium.com/@rekalantar/pytorch-tutorial-dynamic-weight-pruning-for-more-optimized-and-faster-neural-networks-7b337e47987b to do dynamic weight pruning. If the full dataset is too large use a suitable subset size.\n",
    "\n",
    "Use post-training static quantization as well as dynamic quantization as given in: https://pytorch.org/tutorials/recipes/quantization.html to generate a dynamic weight pruning+quantized model. Compare accuracy of the quantized model vs the non-quantized model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d6050",
   "metadata": {},
   "source": [
    "## Importing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69ab7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchsummary\n",
    "from torchvision import models, datasets\n",
    "from timeit import default_timer as timer\n",
    "import torch.quantization as quant\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef547ac",
   "metadata": {},
   "source": [
    "Checking for device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa639fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16a5a68",
   "metadata": {},
   "source": [
    "Loading the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b0082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "# Load and subset the dataset\n",
    "full_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(full_dataset, batch_size=100, shuffle=True)\n",
    "# Load the test dataset\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0359402",
   "metadata": {},
   "source": [
    "# Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71118f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, input_channels, out_planes, stride= 1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, out_planes, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 =  nn.Conv2d(out_planes, out_planes, kernel_size=3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.downsample = downsample\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        # Notice the addition operation in both scenarios\n",
    "        x  = self.skip_add.add(x, identity)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_channels =3 ,num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.input_channels = 64\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.input_channels, kernel_size = 7, stride = 2, padding = 3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.input_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, layers[0], out=64,  stride= 1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], out=128, stride= 2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], out=256, stride= 2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], out=512, stride= 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def _make_layer(self, block, residual_blocks ,out, stride):\n",
    "        downsample = None\n",
    "        layers = []\n",
    "        if stride != 1 or self.input_channels != out:\n",
    "            downsample = nn.Sequential(nn.Conv2d(self.input_channels, out, kernel_size=1, stride= stride),\n",
    "                                       nn.BatchNorm2d(out))\n",
    "        layers.append(block(self.input_channels, out, stride, downsample))\n",
    "        self.input_channels = out\n",
    "        for _ in range(1, residual_blocks):\n",
    "            layers.append(block(self.input_channels, out))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input are quantized\n",
    "        x = self.quant(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dequant(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46b290",
   "metadata": {},
   "source": [
    "Calling the model ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03733d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1915c7",
   "metadata": {},
   "source": [
    "### Defining the optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d46968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81a69f",
   "metadata": {},
   "source": [
    "### Function to count the zero parameters in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a033655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zero_params(model):\n",
    "    zero_count = 0\n",
    "    for param in model.parameters():\n",
    "        zero_count += torch.sum(param == 0).item()\n",
    "    return zero_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d060a9c6",
   "metadata": {},
   "source": [
    "Printing the No.of Zero parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f6c30c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4802\n"
     ]
    }
   ],
   "source": [
    "before_pruning = count_zero_params(model)\n",
    "print(before_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305967b6",
   "metadata": {},
   "source": [
    "Printing the weights of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e0baa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights:\n",
      " Parameter containing:\n",
      "tensor([[[[-0.0809, -0.0459,  0.0629,  ..., -0.0664,  0.0591,  0.0033],\n",
      "          [ 0.0291, -0.0694, -0.0054,  ..., -0.0180, -0.0595,  0.0113],\n",
      "          [ 0.0279,  0.0779, -0.0124,  ...,  0.0150,  0.0679,  0.0358],\n",
      "          ...,\n",
      "          [-0.0058, -0.0513,  0.0510,  ...,  0.0654,  0.0259,  0.0118],\n",
      "          [ 0.0553, -0.0441, -0.0578,  ..., -0.0038,  0.0201,  0.0794],\n",
      "          [ 0.0439,  0.0292,  0.0722,  ..., -0.0177, -0.0498,  0.0376]],\n",
      "\n",
      "         [[-0.0271,  0.0134,  0.0677,  ..., -0.0722,  0.0160,  0.0775],\n",
      "          [ 0.0193, -0.0159,  0.0811,  ...,  0.0671,  0.0367, -0.0198],\n",
      "          [ 0.0666, -0.0800,  0.0025,  ..., -0.0101, -0.0251,  0.0305],\n",
      "          ...,\n",
      "          [-0.0534,  0.0653, -0.0506,  ..., -0.0572, -0.0387,  0.0645],\n",
      "          [ 0.0333, -0.0278,  0.0549,  ..., -0.0267,  0.0116, -0.0498],\n",
      "          [ 0.0232,  0.0253, -0.0682,  ..., -0.0501,  0.0749,  0.0295]],\n",
      "\n",
      "         [[-0.0291,  0.0401,  0.0244,  ...,  0.0327,  0.0024, -0.0044],\n",
      "          [-0.0072,  0.0037,  0.0093,  ..., -0.0824,  0.0559,  0.0029],\n",
      "          [-0.0777, -0.0610,  0.0300,  ..., -0.0198, -0.0274,  0.0389],\n",
      "          ...,\n",
      "          [ 0.0079,  0.0360, -0.0796,  ...,  0.0735,  0.0475, -0.0492],\n",
      "          [ 0.0680, -0.0517,  0.0418,  ..., -0.0089,  0.0525,  0.0185],\n",
      "          [ 0.0193,  0.0467, -0.0463,  ..., -0.0536,  0.0348,  0.0452]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0678, -0.0504,  0.0007,  ..., -0.0327, -0.0638, -0.0386],\n",
      "          [-0.0644,  0.0222, -0.0562,  ...,  0.0579, -0.0556,  0.0192],\n",
      "          [-0.0007,  0.0628,  0.0151,  ..., -0.0097,  0.0094, -0.0674],\n",
      "          ...,\n",
      "          [ 0.0015, -0.0142, -0.0600,  ...,  0.0723,  0.0262,  0.0785],\n",
      "          [-0.0084,  0.0316, -0.0503,  ...,  0.0015,  0.0382, -0.0520],\n",
      "          [ 0.0408,  0.0589,  0.0623,  ...,  0.0576,  0.0794, -0.0752]],\n",
      "\n",
      "         [[ 0.0478, -0.0261,  0.0199,  ...,  0.0221,  0.0673, -0.0258],\n",
      "          [-0.0761,  0.0184, -0.0160,  ...,  0.0115, -0.0704,  0.0164],\n",
      "          [-0.0243,  0.0266,  0.0211,  ..., -0.0562, -0.0767, -0.0011],\n",
      "          ...,\n",
      "          [ 0.0165, -0.0808, -0.0063,  ..., -0.0207,  0.0624,  0.0731],\n",
      "          [ 0.0245,  0.0041,  0.0600,  ...,  0.0140,  0.0617, -0.0287],\n",
      "          [ 0.0077, -0.0739,  0.0430,  ..., -0.0630, -0.0748, -0.0006]],\n",
      "\n",
      "         [[ 0.0758, -0.0474,  0.0316,  ...,  0.0385, -0.0814, -0.0615],\n",
      "          [ 0.0185,  0.0282,  0.0139,  ..., -0.0391, -0.0468,  0.0570],\n",
      "          [-0.0690, -0.0559, -0.0053,  ..., -0.0441, -0.0664,  0.0525],\n",
      "          ...,\n",
      "          [-0.0673,  0.0057,  0.0819,  ..., -0.0325, -0.0457, -0.0273],\n",
      "          [ 0.0462, -0.0813,  0.0201,  ...,  0.0308, -0.0634,  0.0316],\n",
      "          [ 0.0486, -0.0160, -0.0524,  ...,  0.0643, -0.0409, -0.0648]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0410,  0.0196, -0.0722,  ..., -0.0262,  0.0745, -0.0206],\n",
      "          [ 0.0648, -0.0579, -0.0328,  ...,  0.0814,  0.0553, -0.0391],\n",
      "          [-0.0411, -0.0617, -0.0724,  ...,  0.0723,  0.0296,  0.0824],\n",
      "          ...,\n",
      "          [-0.0506, -0.0480, -0.0154,  ..., -0.0684,  0.0747,  0.0216],\n",
      "          [ 0.0021, -0.0682, -0.0106,  ...,  0.0146, -0.0187,  0.0014],\n",
      "          [-0.0589,  0.0234, -0.0077,  ...,  0.0148, -0.0438,  0.0823]],\n",
      "\n",
      "         [[-0.0294, -0.0507, -0.0403,  ...,  0.0177,  0.0351,  0.0738],\n",
      "          [-0.0175, -0.0732,  0.0776,  ..., -0.0410,  0.0351,  0.0277],\n",
      "          [ 0.0823,  0.0294, -0.0618,  ..., -0.0492, -0.0535, -0.0559],\n",
      "          ...,\n",
      "          [-0.0346, -0.0308, -0.0396,  ...,  0.0453,  0.0008, -0.0277],\n",
      "          [-0.0587, -0.0550,  0.0230,  ..., -0.0653, -0.0448,  0.0637],\n",
      "          [ 0.0015, -0.0433,  0.0821,  ..., -0.0674, -0.0516, -0.0468]],\n",
      "\n",
      "         [[ 0.0014, -0.0586,  0.0372,  ..., -0.0461,  0.0441, -0.0164],\n",
      "          [ 0.0655,  0.0357, -0.0656,  ...,  0.0025, -0.0229,  0.0027],\n",
      "          [ 0.0495,  0.0500,  0.0770,  ..., -0.0197,  0.0689, -0.0309],\n",
      "          ...,\n",
      "          [ 0.0012, -0.0713, -0.0301,  ...,  0.0006,  0.0343,  0.0730],\n",
      "          [-0.0412,  0.0708,  0.0777,  ...,  0.0222,  0.0807, -0.0427],\n",
      "          [ 0.0277, -0.0139, -0.0385,  ...,  0.0325, -0.0266,  0.0407]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0189,  0.0590, -0.0546,  ...,  0.0300,  0.0195,  0.0760],\n",
      "          [-0.0755,  0.0803, -0.0006,  ..., -0.0434,  0.0254,  0.0117],\n",
      "          [-0.0751, -0.0605,  0.0462,  ...,  0.0157, -0.0433,  0.0691],\n",
      "          ...,\n",
      "          [ 0.0564,  0.0500, -0.0380,  ...,  0.0278, -0.0399, -0.0567],\n",
      "          [ 0.0796, -0.0682, -0.0162,  ..., -0.0730, -0.0475, -0.0771],\n",
      "          [ 0.0650, -0.0350,  0.0693,  ..., -0.0713, -0.0448, -0.0164]],\n",
      "\n",
      "         [[-0.0622,  0.0328,  0.0144,  ..., -0.0412,  0.0019,  0.0531],\n",
      "          [ 0.0044, -0.0040,  0.0197,  ...,  0.0550, -0.0090,  0.0280],\n",
      "          [-0.0458,  0.0403, -0.0148,  ...,  0.0418, -0.0589,  0.0158],\n",
      "          ...,\n",
      "          [-0.0476, -0.0315,  0.0565,  ...,  0.0736,  0.0448, -0.0566],\n",
      "          [-0.0683,  0.0190,  0.0548,  ...,  0.0362, -0.0394, -0.0427],\n",
      "          [ 0.0438, -0.0654,  0.0263,  ..., -0.0253, -0.0541, -0.0260]],\n",
      "\n",
      "         [[-0.0571,  0.0437,  0.0484,  ..., -0.0736,  0.0718, -0.0623],\n",
      "          [ 0.0640, -0.0734, -0.0490,  ...,  0.0739,  0.0531,  0.0746],\n",
      "          [-0.0723,  0.0262,  0.0812,  ..., -0.0678,  0.0487,  0.0367],\n",
      "          ...,\n",
      "          [ 0.0481,  0.0247, -0.0297,  ...,  0.0707,  0.0319,  0.0445],\n",
      "          [ 0.0342,  0.0451,  0.0484,  ...,  0.0186, -0.0543,  0.0698],\n",
      "          [-0.0597,  0.0126,  0.0811,  ...,  0.0642,  0.0079, -0.0016]]],\n",
      "\n",
      "\n",
      "        [[[-0.0666,  0.0148,  0.0298,  ..., -0.0209, -0.0176, -0.0250],\n",
      "          [ 0.0096, -0.0414, -0.0773,  ...,  0.0465,  0.0294, -0.0451],\n",
      "          [ 0.0372,  0.0501,  0.0145,  ...,  0.0426, -0.0595,  0.0811],\n",
      "          ...,\n",
      "          [ 0.0213, -0.0447, -0.0261,  ..., -0.0233,  0.0405, -0.0055],\n",
      "          [-0.0611,  0.0391, -0.0254,  ...,  0.0166,  0.0600,  0.0575],\n",
      "          [ 0.0648, -0.0213,  0.0197,  ...,  0.0029, -0.0612, -0.0379]],\n",
      "\n",
      "         [[-0.0760,  0.0242, -0.0513,  ...,  0.0286, -0.0312,  0.0734],\n",
      "          [-0.0139, -0.0797, -0.0115,  ..., -0.0759, -0.0716, -0.0637],\n",
      "          [-0.0372,  0.0562, -0.0492,  ...,  0.0305,  0.0175, -0.0564],\n",
      "          ...,\n",
      "          [ 0.0651, -0.0483, -0.0712,  ..., -0.0495,  0.0421, -0.0030],\n",
      "          [ 0.0726, -0.0635,  0.0198,  ...,  0.0644, -0.0064,  0.0059],\n",
      "          [-0.0453, -0.0737, -0.0279,  ..., -0.0465,  0.0595, -0.0759]],\n",
      "\n",
      "         [[ 0.0322, -0.0650,  0.0160,  ...,  0.0747, -0.0675, -0.0008],\n",
      "          [ 0.0514, -0.0215, -0.0360,  ..., -0.0425, -0.0247, -0.0014],\n",
      "          [-0.0009,  0.0773,  0.0404,  ...,  0.0710, -0.0030,  0.0247],\n",
      "          ...,\n",
      "          [ 0.0585,  0.0025,  0.0230,  ...,  0.0443, -0.0789, -0.0362],\n",
      "          [ 0.0691, -0.0342, -0.0376,  ..., -0.0196,  0.0782,  0.0197],\n",
      "          [ 0.0422,  0.0238,  0.0553,  ...,  0.0099,  0.0224, -0.0607]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0313,  0.0126, -0.0325,  ..., -0.0455,  0.0738,  0.0755],\n",
      "          [-0.0660,  0.0432, -0.0480,  ..., -0.0547, -0.0733,  0.0067],\n",
      "          [-0.0128,  0.0508,  0.0172,  ...,  0.0686,  0.0640,  0.0722],\n",
      "          ...,\n",
      "          [-0.0075,  0.0245,  0.0081,  ..., -0.0228, -0.0783, -0.0429],\n",
      "          [-0.0617,  0.0762,  0.0431,  ...,  0.0367,  0.0545, -0.0753],\n",
      "          [-0.0422, -0.0084,  0.0609,  ..., -0.0739, -0.0096, -0.0806]],\n",
      "\n",
      "         [[ 0.0719, -0.0585, -0.0790,  ..., -0.0424,  0.0264, -0.0792],\n",
      "          [ 0.0650,  0.0698, -0.0370,  ...,  0.0203, -0.0047, -0.0344],\n",
      "          [-0.0454,  0.0683, -0.0208,  ..., -0.0429,  0.0756,  0.0025],\n",
      "          ...,\n",
      "          [ 0.0589,  0.0479, -0.0642,  ...,  0.0465,  0.0386,  0.0431],\n",
      "          [-0.0293, -0.0160, -0.0787,  ...,  0.0724,  0.0167, -0.0466],\n",
      "          [ 0.0600,  0.0276, -0.0421,  ..., -0.0352,  0.0545, -0.0540]],\n",
      "\n",
      "         [[ 0.0418,  0.0622, -0.0384,  ...,  0.0384,  0.0158,  0.0223],\n",
      "          [ 0.0213,  0.0646,  0.0745,  ..., -0.0333, -0.0389, -0.0263],\n",
      "          [-0.0735,  0.0060, -0.0810,  ...,  0.0028, -0.0002, -0.0410],\n",
      "          ...,\n",
      "          [ 0.0750,  0.0772,  0.0709,  ...,  0.0652, -0.0203,  0.0286],\n",
      "          [ 0.0072,  0.0585,  0.0666,  ...,  0.0708, -0.0126, -0.0294],\n",
      "          [ 0.0231, -0.0307, -0.0145,  ..., -0.0448, -0.0321,  0.0367]]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original weights:\\n\", model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491e3af5",
   "metadata": {},
   "source": [
    "Function to train the model and to do weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8223ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pruned_model(model, device, train_loader, optimizer, criterion,epochs,prune_epoch):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss : {running_loss / len(train_loader)}')       \n",
    "        \n",
    "        if (epoch+1) % prune_epoch == 0:\n",
    "            prune_model(model, pruning_rate=0.1)\n",
    "            print('Pruning done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b234481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def prune_model(model, pruning_rate=0.1):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "            \n",
    "            # Applying unstructured L1 norm pruning\n",
    "            prune.l1_unstructured(module, name='weight', amount=pruning_rate)\n",
    "            \n",
    "            prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b194957a",
   "metadata": {},
   "source": [
    "Function to Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbcb23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def evaluate_model(model,device):\n",
    "    model = model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            st = time.time()\n",
    "            outputs = model(images)\n",
    "            et = time.time()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct // total} %')\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94eddd",
   "metadata": {},
   "source": [
    "## Calling the function train_model to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14845335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss : 1.464614530801773\n",
      "Epoch [2/15], Loss : 1.0113206499814986\n",
      "Epoch [3/15], Loss : 0.807844424366951\n",
      "Epoch [4/15], Loss : 0.6764954803586006\n",
      "Epoch [5/15], Loss : 0.5684108149409294\n",
      "Pruning done.\n",
      "Epoch [6/15], Loss : 0.47543926364183425\n",
      "Epoch [7/15], Loss : 0.39938797265291215\n",
      "Epoch [8/15], Loss : 0.32666478598117826\n",
      "Epoch [9/15], Loss : 0.2718150601387024\n",
      "Epoch [10/15], Loss : 0.2161609608307481\n",
      "Pruning done.\n",
      "Epoch [11/15], Loss : 0.18002749675512314\n",
      "Epoch [12/15], Loss : 0.1458682178556919\n",
      "Epoch [13/15], Loss : 0.12177217001840472\n",
      "Epoch [14/15], Loss : 0.09855391100049019\n",
      "Epoch [15/15], Loss : 0.09286003717593849\n",
      "Pruning done.\n"
     ]
    }
   ],
   "source": [
    "train_pruned_model(model, device, train_loader, optimizer,criterion, epochs=15,prune_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fb524",
   "metadata": {},
   "source": [
    "Printing the weights after weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddc4f13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned weights:\n",
      " Parameter containing:\n",
      "tensor([[[[-0.1515, -0.0626,  0.1119,  ..., -0.0182,  0.1126,  0.0513],\n",
      "          [-0.0303, -0.1397,  0.0134,  ...,  0.0716,  0.0732,  0.0804],\n",
      "          [-0.0718, -0.0964, -0.2018,  ..., -0.1349, -0.0255, -0.0354],\n",
      "          ...,\n",
      "          [ 0.1216,  0.1531,  0.1881,  ...,  0.0800,  0.0274, -0.0735],\n",
      "          [ 0.0621,  0.0576,  0.0712,  ...,  0.0634,  0.0730,  0.0947],\n",
      "          [ 0.0606,  0.0640,  0.1394,  ...,  0.0561,  0.0151,  0.0721]],\n",
      "\n",
      "         [[-0.0850, -0.0264,  0.1218,  ..., -0.0149,  0.0655,  0.1063],\n",
      "          [-0.0143, -0.0775,  0.1323,  ...,  0.2012,  0.1721,  0.0307],\n",
      "          [-0.0431, -0.2524, -0.1634,  ..., -0.1150, -0.0809, -0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.1793,  0.0341,  ..., -0.0314, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0170,  0.1551,  ...,  0.0482,  0.0787, -0.0219],\n",
      "          [ 0.0211,  0.0000, -0.0432,  ..., -0.0000,  0.1296,  0.0430]],\n",
      "\n",
      "         [[-0.0000,  0.0471,  0.0531,  ..., -0.0000, -0.0267, -0.0512],\n",
      "          [ 0.0874,  0.0563,  0.1218,  ...,  0.0606,  0.1952,  0.0642],\n",
      "          [-0.1175, -0.1781, -0.0698,  ..., -0.0647, -0.0365,  0.0459],\n",
      "          ...,\n",
      "          [ 0.0175,  0.1026, -0.0398,  ...,  0.1009,  0.0926, -0.0884],\n",
      "          [ 0.0000, -0.0756,  0.0615,  ...,  0.0271,  0.0822,  0.0216],\n",
      "          [-0.0000, -0.0212, -0.1116,  ..., -0.0976,  0.0000, -0.0116]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0285, -0.1320, -0.1842,  ...,  0.1958, -0.0620,  0.0000],\n",
      "          [-0.1608, -0.1735, -0.0827,  ...,  0.0720, -0.2970,  0.1006],\n",
      "          [-0.0853,  0.0266,  0.2347,  ..., -0.3215, -0.1043,  0.1521],\n",
      "          ...,\n",
      "          [ 0.1361,  0.1832, -0.0172,  ...,  0.0503,  0.3088,  0.0000],\n",
      "          [-0.0000,  0.0739, -0.1560,  ...,  0.2062,  0.1241, -0.1989],\n",
      "          [-0.0000,  0.0532, -0.0192,  ...,  0.1847, -0.0650, -0.0662]],\n",
      "\n",
      "         [[ 0.2050,  0.0515, -0.0820,  ...,  0.1162, -0.0571, -0.0711],\n",
      "          [ 0.0000, -0.0159,  0.0221,  ..., -0.0930, -0.4175,  0.0185],\n",
      "          [ 0.0161,  0.0657,  0.2185,  ..., -0.4711, -0.2718,  0.1413],\n",
      "          ...,\n",
      "          [ 0.0618, -0.0240, -0.1331,  ..., -0.0566,  0.3326, -0.0218],\n",
      "          [-0.0422, -0.0327, -0.1371,  ...,  0.2412,  0.1638, -0.1383],\n",
      "          [-0.0827, -0.1292, -0.0730,  ...,  0.1327, -0.1434,  0.0751]],\n",
      "\n",
      "         [[ 0.0838, -0.0625, -0.1276,  ...,  0.2163, -0.0697, -0.0316],\n",
      "          [-0.0565, -0.0942,  0.0000,  ..., -0.0000, -0.2745,  0.0813],\n",
      "          [-0.1385, -0.0801,  0.1932,  ..., -0.2396, -0.1118,  0.2434],\n",
      "          ...,\n",
      "          [-0.0767,  0.1059,  0.0414,  ...,  0.0725,  0.2775, -0.0950],\n",
      "          [ 0.0000, -0.0515, -0.1000,  ...,  0.2797,  0.0000, -0.1086],\n",
      "          [ 0.0403,  0.0314, -0.0582,  ...,  0.2563, -0.1679, -0.0575]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0705,  0.0736, -0.0447,  ...,  0.0000,  0.0754, -0.0145],\n",
      "          [ 0.0893, -0.0126,  0.0000,  ...,  0.1436,  0.0962,  0.0000],\n",
      "          [-0.0521, -0.0678, -0.0834,  ...,  0.1344,  0.0697,  0.1246],\n",
      "          ...,\n",
      "          [-0.0898, -0.0778, -0.0110,  ..., -0.0719,  0.0665,  0.0209],\n",
      "          [-0.0618, -0.1198, -0.0570,  ..., -0.0365, -0.0587,  0.0000],\n",
      "          [-0.1135, -0.0277, -0.0697,  ..., -0.0183, -0.0724,  0.0561]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0228,  ...,  0.0321,  0.0231,  0.0705],\n",
      "          [ 0.0000, -0.0363,  0.0988,  ..., -0.0000,  0.0432,  0.0437],\n",
      "          [ 0.0770,  0.0266, -0.0640,  ..., -0.0000, -0.0345, -0.0366],\n",
      "          ...,\n",
      "          [-0.0473, -0.0325, -0.0000,  ...,  0.0606, -0.0000, -0.0261],\n",
      "          [-0.1073, -0.0860, -0.0000,  ..., -0.1024, -0.0812,  0.0452],\n",
      "          [-0.0555, -0.0903,  0.0273,  ..., -0.0984, -0.0829, -0.0830]],\n",
      "\n",
      "         [[ 0.0539,  0.0000,  0.0657,  ..., -0.0419,  0.0234, -0.0191],\n",
      "          [ 0.1255,  0.0983, -0.0279,  ...,  0.0315, -0.0000,  0.0326],\n",
      "          [ 0.0782,  0.0693,  0.0861,  ...,  0.0167,  0.0831, -0.0000],\n",
      "          ...,\n",
      "          [ 0.0187, -0.0339,  0.0103,  ...,  0.0118,  0.0400,  0.0745],\n",
      "          [-0.0740,  0.0666,  0.0667,  ..., -0.0000,  0.0543, -0.0538],\n",
      "          [-0.0226, -0.0431, -0.0785,  ...,  0.0129, -0.0398,  0.0222]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0178,  0.1512,  0.0879,  ...,  0.1292,  0.0643,  0.0767],\n",
      "          [-0.0189,  0.1360,  0.1105,  ...,  0.1049,  0.0635, -0.0286],\n",
      "          [-0.1387, -0.1274, -0.0105,  ..., -0.0897, -0.1488, -0.0208],\n",
      "          ...,\n",
      "          [ 0.0126,  0.0712, -0.1435,  ...,  0.0842, -0.0385, -0.1796],\n",
      "          [ 0.0500, -0.1196, -0.1369,  ..., -0.1662, -0.1154, -0.1350],\n",
      "          [ 0.0536, -0.0533,  0.0655,  ..., -0.0336,  0.0118,  0.0868]],\n",
      "\n",
      "         [[-0.0119,  0.1002,  0.1064,  ...,  0.0000,  0.0645,  0.1003],\n",
      "          [ 0.0538,  0.0000,  0.0409,  ...,  0.0683, -0.0227, -0.0356],\n",
      "          [-0.0989, -0.0411, -0.1113,  ..., -0.1022, -0.1529, -0.0551],\n",
      "          ...,\n",
      "          [ 0.0305,  0.1040,  0.0754,  ...,  0.2150,  0.1135, -0.1258],\n",
      "          [-0.0577,  0.0000, -0.0299,  ..., -0.0893, -0.1723, -0.1658],\n",
      "          [ 0.0520, -0.1002, -0.0293,  ..., -0.0930, -0.1295, -0.0275]],\n",
      "\n",
      "         [[-0.0758,  0.0000,  0.0000,  ..., -0.2059, -0.0372, -0.1455],\n",
      "          [ 0.0000, -0.1974, -0.1810,  ..., -0.0793, -0.0761, -0.0430],\n",
      "          [-0.2248, -0.1705, -0.1205,  ..., -0.2923, -0.0492,  0.0000],\n",
      "          ...,\n",
      "          [ 0.1228,  0.2190,  0.1007,  ...,  0.3773,  0.2741,  0.1298],\n",
      "          [ 0.0718,  0.0910,  0.0642,  ...,  0.0190, -0.0620,  0.0501],\n",
      "          [ 0.0000,  0.0438,  0.0998,  ...,  0.0677, -0.0000,  0.0482]]],\n",
      "\n",
      "\n",
      "        [[[-0.1618, -0.0753,  0.0000,  ...,  0.0000,  0.0150, -0.0333],\n",
      "          [-0.0000, -0.0438, -0.1480,  ..., -0.1013,  0.0000, -0.0807],\n",
      "          [ 0.1518,  0.2215,  0.1738,  ...,  0.0900, -0.0224,  0.0843],\n",
      "          ...,\n",
      "          [-0.0666, -0.1003, -0.0843,  ..., -0.0272,  0.0809,  0.0000],\n",
      "          [-0.1392,  0.0412, -0.0997,  ..., -0.0491,  0.0554,  0.0895],\n",
      "          [ 0.0239,  0.0149, -0.0000,  ..., -0.0541, -0.1308, -0.0247]],\n",
      "\n",
      "         [[-0.1364, -0.0556, -0.0868,  ...,  0.0309, -0.0000,  0.1104],\n",
      "          [-0.0000, -0.0993, -0.1070,  ..., -0.2908, -0.1609, -0.1150],\n",
      "          [ 0.0565,  0.2027,  0.0864,  ..., -0.0271, -0.0525, -0.1400],\n",
      "          ...,\n",
      "          [-0.0284, -0.0736, -0.1101,  ..., -0.0951,  0.0162, -0.0863],\n",
      "          [-0.0184, -0.0391, -0.0000,  ..., -0.0000, -0.0482, -0.0000],\n",
      "          [-0.0877, -0.0144, -0.0150,  ..., -0.0737, -0.0459, -0.1254]],\n",
      "\n",
      "         [[-0.0456, -0.1508, -0.0426,  ...,  0.0363, -0.0636, -0.0179],\n",
      "          [ 0.0523, -0.0241, -0.1171,  ..., -0.2649, -0.1369, -0.0887],\n",
      "          [ 0.1312,  0.2663,  0.2230,  ...,  0.0663, -0.0558, -0.0600],\n",
      "          ...,\n",
      "          [ 0.0649,  0.0738,  0.0837,  ...,  0.1140,  0.0125, -0.0233],\n",
      "          [ 0.0276,  0.0287, -0.0000,  ..., -0.0000,  0.1323,  0.0984],\n",
      "          [-0.0170,  0.0804,  0.1015,  ...,  0.0417,  0.0227, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0504, -0.0000, -0.0570,  ..., -0.0806,  0.0181,  0.0178],\n",
      "          [-0.0754,  0.0000, -0.0911,  ..., -0.0934, -0.1333, -0.0664],\n",
      "          [-0.0000,  0.0253, -0.0371,  ...,  0.0467,  0.0282,  0.0136],\n",
      "          ...,\n",
      "          [-0.0345, -0.0000, -0.0513,  ..., -0.0886, -0.1243, -0.1105],\n",
      "          [-0.0733,  0.0552, -0.0125,  ..., -0.0187,  0.0348, -0.1138],\n",
      "          [-0.0284, -0.0250,  0.0000,  ..., -0.1236, -0.0481, -0.1276]],\n",
      "\n",
      "         [[ 0.0864, -0.0684, -0.0886,  ..., -0.0510,  0.0000, -0.0962],\n",
      "          [ 0.0570,  0.0587, -0.0633,  ..., -0.0000, -0.0411, -0.0836],\n",
      "          [-0.0356,  0.0485, -0.0645,  ..., -0.0645,  0.0454, -0.0436],\n",
      "          ...,\n",
      "          [ 0.0494,  0.0371, -0.0877,  ...,  0.0000,  0.0229,  0.0155],\n",
      "          [-0.0228, -0.0104, -0.0970,  ...,  0.0560,  0.0311, -0.0433],\n",
      "          [ 0.0927,  0.0427, -0.0485,  ..., -0.0444,  0.0515, -0.0610]],\n",
      "\n",
      "         [[ 0.0859,  0.0871, -0.0171,  ...,  0.0628,  0.0334,  0.0456],\n",
      "          [ 0.0335,  0.0771,  0.0744,  ..., -0.0455, -0.0598, -0.0547],\n",
      "          [-0.0483,  0.0000, -0.1049,  ..., -0.0000, -0.0132, -0.0666],\n",
      "          ...,\n",
      "          [ 0.0676,  0.0697,  0.0500,  ...,  0.0423, -0.0000,  0.0282],\n",
      "          [ 0.0123,  0.0622,  0.0470,  ...,  0.0688,  0.0277, -0.0000],\n",
      "          [ 0.0521, -0.0137, -0.0132,  ..., -0.0351, -0.0000,  0.0560]]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Pruned weights:\\n\", model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90853f7",
   "metadata": {},
   "source": [
    "No.of Zero parameters after weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baa58717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117203\n"
     ]
    }
   ],
   "source": [
    "after_pruning = count_zero_params(model)\n",
    "print(after_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220743f",
   "metadata": {},
   "source": [
    "Evaluating the model and printing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b29c01b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================AFTER WEIGHT PRUNING========================================\n",
      "Accuracy: 75 %\n",
      "Elapsed time = 33.2420 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device ='cpu'\n",
    "print(\"=====================================AFTER WEIGHT PRUNING========================================\")\n",
    "evaluate_model(model,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a940b",
   "metadata": {},
   "source": [
    "Function to print the size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3b8b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model,path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print('Size (MB):', os.path.getsize(path)/1e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94027ba7",
   "metadata": {},
   "source": [
    "Printing the size of the model before quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe731be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================BEFORE QUANTIZATION========================================\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "Size of the model Before Dynamic quantization\n",
      "Size (MB): 44830.942\n"
     ]
    }
   ],
   "source": [
    "print(\"=====================================BEFORE QUANTIZATION========================================\")\n",
    "print(model)\n",
    "print('Size of the model Before Dynamic quantization')\n",
    "print_size_of_model(model,path=\"FinalTask11.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9a47e1",
   "metadata": {},
   "source": [
    "# Dynamic quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd34c5b",
   "metadata": {},
   "source": [
    "Doing dynamic quantization for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3e0589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dynamic_quantized = torch.quantization.quantize_dynamic(\n",
    "    model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f75050",
   "metadata": {},
   "source": [
    "Printing the model and size of it after dynamic quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07f7f8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================DYNAMIC QUANTIZATION========================================\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "Size of the model After Dynamic quantization\n",
      "Size (MB): 44816.372\n"
     ]
    }
   ],
   "source": [
    "print(\"=====================================DYNAMIC QUANTIZATION========================================\")\n",
    "print(model_dynamic_quantized)\n",
    "print('Size of the model After Dynamic quantization')\n",
    "print_size_of_model(model_dynamic_quantized,path=\"FinalTask11_dynamic.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ecada",
   "metadata": {},
   "source": [
    "Evaluating and printing the accuracy of the model after dynamic quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5554f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================ACCURACY AFTER DYNAMIC QUANTIZATION=======================================\n",
      "Accuracy: 76 %\n",
      "Elapsed time = 27.3499 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device ='cpu'\n",
    "print(\"=====================================ACCURACY AFTER DYNAMIC QUANTIZATION=======================================\")\n",
    "evaluate_model(model_dynamic_quantized,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631de5ab",
   "metadata": {},
   "source": [
    "# Static Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea371e",
   "metadata": {},
   "source": [
    "Doing Static quantization for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e8b767e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(\n",
      "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (bn1): BatchNorm2d(\n",
      "    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (relu): ReLU(\n",
      "    inplace=True\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(\n",
      "          64, 128, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "        (1): BatchNorm2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(\n",
      "          128, 256, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "        (1): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2)\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "        (1): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (activation_post_process): HistogramObserver()\n",
      "        )\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(\n",
      "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (relu): ReLU(\n",
      "        inplace=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (conv2): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (bn2): BatchNorm2d(\n",
      "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): HistogramObserver()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.08372426778078079, zero_point=64, padding=(3, 3))\n",
      "  (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.24363915622234344, zero_point=73, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.1066269651055336, zero_point=71, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.16372664272785187, zero_point=36\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.2313399761915207, zero_point=67, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10352001339197159, zero_point=70, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.15603339672088623, zero_point=42\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.18175674974918365, zero_point=68, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.07328754663467407, zero_point=66, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.10529658198356628, zero_point=65)\n",
      "        (1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.12589508295059204, zero_point=62\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.11061088740825653, zero_point=67, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09679064154624939, zero_point=71, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.1364017128944397, zero_point=50\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.13088560104370117, zero_point=59, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.09548082202672958, zero_point=60, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.07414333522319794, zero_point=65)\n",
      "        (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.1538567841053009, zero_point=59\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.1115313246846199, zero_point=56, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.16311554610729218, zero_point=61, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.17585603892803192, zero_point=43\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.140579953789711, zero_point=63, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1944303810596466, zero_point=65, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.14999467134475708, zero_point=61)\n",
      "        (1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.2976078987121582, zero_point=57\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.17147067189216614, zero_point=64, padding=(1, 1))\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.3242853879928589, zero_point=69, padding=(1, 1))\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): QFunctional(\n",
      "        scale=0.3143630027770996, zero_point=59\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): DynamicQuantizedLinear(in_features=512, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_dynamic_quantized.eval()\n",
    "model_dynamic_quantized.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "static_quantized = torch.quantization.prepare(model_dynamic_quantized, inplace=True)\n",
    "print(static_quantized)\n",
    "with torch.no_grad():\n",
    "    for data, target in train_loader:\n",
    "        static_quantized(data)\n",
    "static_quantized = torch.quantization.convert(static_quantized, inplace=True)\n",
    "print(static_quantized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3af0fc",
   "metadata": {},
   "source": [
    "Printing the model and size of it after Static quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c31a9f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model After Static quantization\n",
      "Size (MB): 11420.771\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model After Static quantization')\n",
    "print_size_of_model(static_quantized,path=\"FinalTask11_static.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078d61c2",
   "metadata": {},
   "source": [
    "Evaluating and finding the accuracy of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "463f1e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================ACCURACY AFTER STATIC QUANTIZATION=======================================\n",
      "Accuracy: 76 %\n",
      "Elapsed time = 10.3257 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device ='cpu'\n",
    "print(\"=====================================ACCURACY AFTER STATIC QUANTIZATION=======================================\")\n",
    "evaluate_model(static_quantized,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94643ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
